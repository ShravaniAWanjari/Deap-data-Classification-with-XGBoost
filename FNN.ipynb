{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load and normalize data\n",
    "with open('out/data_training.npy', 'rb') as fileTrain:\n",
    "    X_train = np.load(fileTrain)\n",
    "\n",
    "with open('out/label_training.npy', 'rb') as fileTrainL:\n",
    "    Y_train = np.load(fileTrainL)\n",
    "\n",
    "X_train = normalize(X_train)\n",
    "Y_train = np.column_stack((\n",
    "    np.ravel(Y_train[:, [0]]),  # Arousal\n",
    "    np.ravel(Y_train[:, [1]]),  # Valence\n",
    "    np.ravel(Y_train[:, [2]]),  # Dominance\n",
    "    np.ravel(Y_train[:, [3]])   # Liking\n",
    "))\n",
    "\n",
    "with open('out/data_validation.npy', 'rb') as fileValid:\n",
    "    X_val = np.load(fileValid)\n",
    "\n",
    "with open('out/label_validation.npy', 'rb') as fileValidL:\n",
    "    Y_val = np.load(fileValidL)\n",
    "\n",
    "X_val = normalize(X_val)\n",
    "Y_val = np.column_stack((\n",
    "    np.ravel(Y_val[:, [0]]),  # Arousal\n",
    "    np.ravel(Y_val[:, [1]]),  # Valence\n",
    "    np.ravel(Y_val[:, [2]]),  # Dominance\n",
    "    np.ravel(Y_val[:, [3]])   # Liking\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fnn_with_dropout(X_train, Y_train, X_val, Y_val, feature_name):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),  # Dropout layer with 30% dropout rate\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),  # Dropout layer with 30% dropout rate\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),  # Dropout layer with 30% dropout rate\n",
    "        tf.keras.layers.Dense(1)  # Output layer for single regression target\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "    history = model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_data=(X_val, Y_val), verbose=1)\n",
    "\n",
    "    Y_val_pred = model.predict(X_val).flatten()\n",
    "\n",
    "    mse = mean_squared_error(Y_val, Y_val_pred)\n",
    "    std_dev = np.std(Y_val_pred - Y_val)\n",
    "    accuracy = accuracy_score(Y_val > 5, Y_val_pred > 5)\n",
    "    f1 = f1_score(Y_val > 5, Y_val_pred > 5)\n",
    "\n",
    "    print(f\"{feature_name} - Validation MSE: {mse:.4f}\")\n",
    "    print(f\"{feature_name} - Validation Std Dev: {std_dev:.4f}\")\n",
    "    print(f\"{feature_name} - Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{feature_name} - Validation F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 4.9918 - mae: 1.8450 - val_loss: 4.0032 - val_mae: 1.6686\n",
      "Epoch 2/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 4.1469 - mae: 1.6932 - val_loss: 3.8612 - val_mae: 1.6333\n",
      "Epoch 3/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 3.9782 - mae: 1.6535 - val_loss: 3.8090 - val_mae: 1.6202\n",
      "Epoch 4/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 3.9040 - mae: 1.6344 - val_loss: 3.7900 - val_mae: 1.6178\n",
      "Epoch 5/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 3.8452 - mae: 1.6193 - val_loss: 3.7581 - val_mae: 1.6082\n",
      "Epoch 6/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 3.8114 - mae: 1.6107 - val_loss: 3.6774 - val_mae: 1.5828\n",
      "Epoch 7/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 3.7822 - mae: 1.6010 - val_loss: 3.6673 - val_mae: 1.5791\n",
      "Epoch 8/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3ms/step - loss: 3.7621 - mae: 1.5954 - val_loss: 3.6198 - val_mae: 1.5656\n",
      "Epoch 9/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 3.7506 - mae: 1.5918 - val_loss: 3.6112 - val_mae: 1.5630\n",
      "Epoch 10/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 3.7307 - mae: 1.5864 - val_loss: 3.6067 - val_mae: 1.5699\n",
      "Epoch 11/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 3.7071 - mae: 1.5794 - val_loss: 3.5787 - val_mae: 1.5589\n",
      "Epoch 12/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 3.6933 - mae: 1.5764 - val_loss: 3.5802 - val_mae: 1.5470\n",
      "Epoch 13/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 3.6586 - mae: 1.5675 - val_loss: 3.5743 - val_mae: 1.5637\n",
      "Epoch 14/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 3.6691 - mae: 1.5696 - val_loss: 3.5146 - val_mae: 1.5370\n",
      "Epoch 15/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 3.6427 - mae: 1.5619 - val_loss: 3.5154 - val_mae: 1.5376\n",
      "Epoch 16/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 3.6354 - mae: 1.5594 - val_loss: 3.5011 - val_mae: 1.5327\n",
      "Epoch 17/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 3.6315 - mae: 1.5587 - val_loss: 3.4822 - val_mae: 1.5297\n",
      "Epoch 18/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 3.6115 - mae: 1.5542 - val_loss: 3.5231 - val_mae: 1.5482\n",
      "Epoch 19/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 3.6092 - mae: 1.5528 - val_loss: 3.4629 - val_mae: 1.5206\n",
      "Epoch 20/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 3.5875 - mae: 1.5461 - val_loss: 3.4665 - val_mae: 1.5309\n",
      "Epoch 21/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 3.5805 - mae: 1.5441 - val_loss: 3.4761 - val_mae: 1.5286\n",
      "Epoch 22/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 3.5877 - mae: 1.5463 - val_loss: 3.4781 - val_mae: 1.5360\n",
      "Epoch 23/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 3.5738 - mae: 1.5431 - val_loss: 3.4566 - val_mae: 1.5221\n",
      "Epoch 24/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 3.5640 - mae: 1.5404 - val_loss: 3.4499 - val_mae: 1.5248\n",
      "Epoch 25/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 3.5535 - mae: 1.5370 - val_loss: 3.4412 - val_mae: 1.5229\n",
      "Epoch 26/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 3.5370 - mae: 1.5335 - val_loss: 3.4315 - val_mae: 1.5219\n",
      "Epoch 27/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 3.5476 - mae: 1.5363 - val_loss: 3.4167 - val_mae: 1.5152\n",
      "Epoch 28/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 3.5517 - mae: 1.5353 - val_loss: 3.4248 - val_mae: 1.5124\n",
      "Epoch 29/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 3.5383 - mae: 1.5311 - val_loss: 3.4157 - val_mae: 1.5186\n",
      "Epoch 30/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 3.5352 - mae: 1.5311 - val_loss: 3.3959 - val_mae: 1.5029\n",
      "Epoch 31/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 3.5324 - mae: 1.5296 - val_loss: 3.4071 - val_mae: 1.5106\n",
      "Epoch 32/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 3.5183 - mae: 1.5260 - val_loss: 3.3958 - val_mae: 1.5104\n",
      "Epoch 33/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 3.5234 - mae: 1.5286 - val_loss: 3.3764 - val_mae: 1.5002\n",
      "Epoch 34/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 3.5004 - mae: 1.5232 - val_loss: 3.4162 - val_mae: 1.5226\n",
      "Epoch 35/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 3.5138 - mae: 1.5262 - val_loss: 3.3609 - val_mae: 1.5000\n",
      "Epoch 36/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 3.5097 - mae: 1.5231 - val_loss: 3.3947 - val_mae: 1.5132\n",
      "Epoch 37/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 3.5052 - mae: 1.5241 - val_loss: 3.3575 - val_mae: 1.4949\n",
      "Epoch 38/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 3.4976 - mae: 1.5203 - val_loss: 3.3494 - val_mae: 1.4951\n",
      "Epoch 39/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 3.4977 - mae: 1.5218 - val_loss: 3.3992 - val_mae: 1.5168\n",
      "Epoch 40/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2ms/step - loss: 3.4932 - mae: 1.5203 - val_loss: 3.3684 - val_mae: 1.4981\n",
      "Epoch 41/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 3.4853 - mae: 1.5175 - val_loss: 3.3175 - val_mae: 1.4787\n",
      "Epoch 42/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 3.4864 - mae: 1.5175 - val_loss: 3.3510 - val_mae: 1.4909\n",
      "Epoch 43/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 3.4892 - mae: 1.5174 - val_loss: 3.3295 - val_mae: 1.4852\n",
      "Epoch 44/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 3.4870 - mae: 1.5177 - val_loss: 3.3323 - val_mae: 1.4900\n",
      "Epoch 45/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 3.4684 - mae: 1.5121 - val_loss: 3.3584 - val_mae: 1.5008\n",
      "Epoch 46/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 23ms/step - loss: 3.4863 - mae: 1.5171 - val_loss: 3.3662 - val_mae: 1.5054\n",
      "Epoch 47/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 3.4628 - mae: 1.5105 - val_loss: 3.3430 - val_mae: 1.4962\n",
      "Epoch 48/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 3.4529 - mae: 1.5089 - val_loss: 3.3652 - val_mae: 1.4970\n",
      "Epoch 49/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 3.4612 - mae: 1.5112 - val_loss: 3.3520 - val_mae: 1.5034\n",
      "Epoch 50/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 3.4568 - mae: 1.5089 - val_loss: 3.3548 - val_mae: 1.5026\n",
      "\u001b[1m2440/2440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "Arousal - Validation MSE: 3.3548\n",
      "Arousal - Validation Std Dev: 1.8291\n",
      "Arousal - Validation Accuracy: 0.6869\n",
      "Arousal - Validation F1-score: 0.7187\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_fnn_with_dropout(X_train, Y_train[:, 0], X_val, Y_val[:, 0], \"Arousal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 4.3836 - mae: 1.7033 - val_loss: 3.4613 - val_mae: 1.5363\n",
      "Epoch 2/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 3.5985 - mae: 1.5526 - val_loss: 3.4004 - val_mae: 1.5269\n",
      "Epoch 3/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 3.4547 - mae: 1.5163 - val_loss: 3.3592 - val_mae: 1.5109\n",
      "Epoch 4/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 3.3924 - mae: 1.4992 - val_loss: 3.3053 - val_mae: 1.4954\n",
      "Epoch 5/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 3.3427 - mae: 1.4841 - val_loss: 3.2588 - val_mae: 1.4753\n",
      "Epoch 6/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 3.3374 - mae: 1.4823 - val_loss: 3.2251 - val_mae: 1.4468\n",
      "Epoch 7/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 3.3039 - mae: 1.4731 - val_loss: 3.1839 - val_mae: 1.4435\n",
      "Epoch 8/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 3.2774 - mae: 1.4657 - val_loss: 3.1679 - val_mae: 1.4271\n",
      "Epoch 9/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 3.2583 - mae: 1.4601 - val_loss: 3.1418 - val_mae: 1.4392\n",
      "Epoch 10/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 3.2395 - mae: 1.4541 - val_loss: 3.1369 - val_mae: 1.4421\n",
      "Epoch 11/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 3.2210 - mae: 1.4478 - val_loss: 3.1033 - val_mae: 1.4300\n",
      "Epoch 12/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 3.2064 - mae: 1.4449 - val_loss: 3.0889 - val_mae: 1.4206\n",
      "Epoch 13/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 14ms/step - loss: 3.2021 - mae: 1.4423 - val_loss: 3.0731 - val_mae: 1.4170\n",
      "Epoch 14/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 3.1833 - mae: 1.4371 - val_loss: 3.0752 - val_mae: 1.4230\n",
      "Epoch 15/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - loss: 3.1728 - mae: 1.4333 - val_loss: 3.0565 - val_mae: 1.4096\n",
      "Epoch 16/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 3.1595 - mae: 1.4302 - val_loss: 3.0379 - val_mae: 1.4106\n",
      "Epoch 17/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3ms/step - loss: 3.1464 - mae: 1.4271 - val_loss: 3.0462 - val_mae: 1.4175\n",
      "Epoch 18/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 3.1418 - mae: 1.4242 - val_loss: 3.0336 - val_mae: 1.4130\n",
      "Epoch 19/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 3.1369 - mae: 1.4237 - val_loss: 3.0538 - val_mae: 1.4259\n",
      "Epoch 20/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 3.1223 - mae: 1.4192 - val_loss: 3.0176 - val_mae: 1.4012\n",
      "Epoch 21/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - loss: 3.1268 - mae: 1.4205 - val_loss: 3.0128 - val_mae: 1.4062\n",
      "Epoch 22/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 3.1162 - mae: 1.4169 - val_loss: 2.9936 - val_mae: 1.3971\n",
      "Epoch 23/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 3.1124 - mae: 1.4140 - val_loss: 3.0059 - val_mae: 1.3989\n",
      "Epoch 24/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 3.1029 - mae: 1.4130 - val_loss: 2.9672 - val_mae: 1.3813\n",
      "Epoch 25/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 3.1058 - mae: 1.4141 - val_loss: 2.9886 - val_mae: 1.3911\n",
      "Epoch 26/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 3.0966 - mae: 1.4116 - val_loss: 2.9885 - val_mae: 1.4009\n",
      "Epoch 27/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 3.0845 - mae: 1.4077 - val_loss: 2.9962 - val_mae: 1.3972\n",
      "Epoch 28/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 3.0818 - mae: 1.4063 - val_loss: 2.9866 - val_mae: 1.4001\n",
      "Epoch 29/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 3.0715 - mae: 1.4032 - val_loss: 2.9803 - val_mae: 1.4025\n",
      "Epoch 30/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 3.0611 - mae: 1.4016 - val_loss: 2.9461 - val_mae: 1.3812\n",
      "Epoch 31/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 3.0722 - mae: 1.4039 - val_loss: 2.9636 - val_mae: 1.3943\n",
      "Epoch 32/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 3.0719 - mae: 1.4042 - val_loss: 2.9302 - val_mae: 1.3744\n",
      "Epoch 33/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 3.0559 - mae: 1.3997 - val_loss: 2.9498 - val_mae: 1.3860\n",
      "Epoch 34/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 3.0597 - mae: 1.4000 - val_loss: 2.9391 - val_mae: 1.3853\n",
      "Epoch 35/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 3.0541 - mae: 1.3988 - val_loss: 2.9672 - val_mae: 1.3989\n",
      "Epoch 36/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 3.0423 - mae: 1.3953 - val_loss: 2.9214 - val_mae: 1.3631\n",
      "Epoch 37/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 3.0501 - mae: 1.3981 - val_loss: 2.9581 - val_mae: 1.3983\n",
      "Epoch 38/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 3.0500 - mae: 1.3966 - val_loss: 2.9511 - val_mae: 1.3939\n",
      "Epoch 39/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 3.0432 - mae: 1.3960 - val_loss: 2.9404 - val_mae: 1.3874\n",
      "Epoch 40/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - loss: 3.0407 - mae: 1.3948 - val_loss: 2.9378 - val_mae: 1.3877\n",
      "Epoch 41/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 3.0343 - mae: 1.3919 - val_loss: 2.9782 - val_mae: 1.4072\n",
      "Epoch 42/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2303s\u001b[0m 157ms/step - loss: 3.0366 - mae: 1.3938 - val_loss: 2.9262 - val_mae: 1.3779\n",
      "Epoch 43/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 3.0341 - mae: 1.3929 - val_loss: 2.8800 - val_mae: 1.3539\n",
      "Epoch 44/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 3.0184 - mae: 1.3877 - val_loss: 2.9487 - val_mae: 1.3941\n",
      "Epoch 45/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 3.0222 - mae: 1.3880 - val_loss: 2.9023 - val_mae: 1.3746\n",
      "Epoch 46/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - loss: 3.0272 - mae: 1.3909 - val_loss: 2.9154 - val_mae: 1.3810\n",
      "Epoch 47/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 3.0198 - mae: 1.3896 - val_loss: 2.8823 - val_mae: 1.3642\n",
      "Epoch 48/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 3.0138 - mae: 1.3870 - val_loss: 2.9021 - val_mae: 1.3742\n",
      "Epoch 49/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 3.0165 - mae: 1.3878 - val_loss: 2.8918 - val_mae: 1.3726\n",
      "Epoch 50/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 3.0184 - mae: 1.3887 - val_loss: 2.9019 - val_mae: 1.3753\n",
      "\u001b[1m2440/2440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 629us/step\n",
      "Valence - Validation MSE: 2.9019\n",
      "Valence - Validation Std Dev: 1.6972\n",
      "Valence - Validation Accuracy: 0.6967\n",
      "Valence - Validation F1-score: 0.7382\n"
     ]
    }
   ],
   "source": [
    "train_fnn_with_dropout(X_train, Y_train[:, 1], X_val, Y_val[:, 1], \"Valence\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 4.2894 - mae: 1.6755 - val_loss: 3.3350 - val_mae: 1.4840\n",
      "Epoch 2/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 3.4958 - mae: 1.5197 - val_loss: 3.2497 - val_mae: 1.4560\n",
      "Epoch 3/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 3.3619 - mae: 1.4846 - val_loss: 3.1992 - val_mae: 1.4424\n",
      "Epoch 4/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 3.2787 - mae: 1.4620 - val_loss: 3.1364 - val_mae: 1.4188\n",
      "Epoch 5/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 3.2465 - mae: 1.4525 - val_loss: 3.1385 - val_mae: 1.4319\n",
      "Epoch 6/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 3.2173 - mae: 1.4437 - val_loss: 3.1080 - val_mae: 1.4244\n",
      "Epoch 7/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 3.1799 - mae: 1.4335 - val_loss: 3.0666 - val_mae: 1.4132\n",
      "Epoch 8/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 3.1646 - mae: 1.4286 - val_loss: 3.0548 - val_mae: 1.4012\n",
      "Epoch 9/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 3.1428 - mae: 1.4229 - val_loss: 3.0937 - val_mae: 1.4344\n",
      "Epoch 10/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 3.1361 - mae: 1.4195 - val_loss: 3.0319 - val_mae: 1.4071\n",
      "Epoch 11/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 3.1183 - mae: 1.4153 - val_loss: 3.0042 - val_mae: 1.3903\n",
      "Epoch 12/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 3.1078 - mae: 1.4100 - val_loss: 2.9768 - val_mae: 1.3720\n",
      "Epoch 13/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 3.0893 - mae: 1.4058 - val_loss: 2.9823 - val_mae: 1.3880\n",
      "Epoch 14/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 3.0855 - mae: 1.4045 - val_loss: 2.9580 - val_mae: 1.3756\n",
      "Epoch 15/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1506s\u001b[0m 103ms/step - loss: 3.0686 - mae: 1.3991 - val_loss: 2.9620 - val_mae: 1.3664\n",
      "Epoch 16/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - loss: 3.0585 - mae: 1.3970 - val_loss: 2.9554 - val_mae: 1.3890\n",
      "Epoch 17/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - loss: 3.0429 - mae: 1.3912 - val_loss: 2.9530 - val_mae: 1.3741\n",
      "Epoch 18/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - loss: 3.0508 - mae: 1.3942 - val_loss: 2.9288 - val_mae: 1.3746\n",
      "Epoch 19/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - loss: 3.0293 - mae: 1.3881 - val_loss: 2.9246 - val_mae: 1.3663\n",
      "Epoch 20/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - loss: 3.0288 - mae: 1.3881 - val_loss: 2.9043 - val_mae: 1.3553\n",
      "Epoch 21/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 3.0290 - mae: 1.3867 - val_loss: 2.8978 - val_mae: 1.3681\n",
      "Epoch 22/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 3.0193 - mae: 1.3842 - val_loss: 2.8942 - val_mae: 1.3580\n",
      "Epoch 23/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 3.0009 - mae: 1.3796 - val_loss: 2.8938 - val_mae: 1.3582\n",
      "Epoch 24/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 3.0029 - mae: 1.3815 - val_loss: 2.8716 - val_mae: 1.3513\n",
      "Epoch 25/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 2.9971 - mae: 1.3781 - val_loss: 2.8836 - val_mae: 1.3559\n",
      "Epoch 26/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 2.9966 - mae: 1.3778 - val_loss: 2.8713 - val_mae: 1.3572\n",
      "Epoch 27/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 2.9907 - mae: 1.3762 - val_loss: 2.8602 - val_mae: 1.3483\n",
      "Epoch 28/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 2.9870 - mae: 1.3764 - val_loss: 2.8755 - val_mae: 1.3565\n",
      "Epoch 29/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 2.9756 - mae: 1.3731 - val_loss: 2.8651 - val_mae: 1.3569\n",
      "Epoch 30/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 2.9703 - mae: 1.3710 - val_loss: 2.8430 - val_mae: 1.3493\n",
      "Epoch 31/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 2.9609 - mae: 1.3669 - val_loss: 2.8730 - val_mae: 1.3640\n",
      "Epoch 32/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 2.9647 - mae: 1.3679 - val_loss: 2.8437 - val_mae: 1.3542\n",
      "Epoch 33/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 2.9458 - mae: 1.3642 - val_loss: 2.8380 - val_mae: 1.3364\n",
      "Epoch 34/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 2.9525 - mae: 1.3661 - val_loss: 2.8613 - val_mae: 1.3615\n",
      "Epoch 35/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 2.9477 - mae: 1.3642 - val_loss: 2.8214 - val_mae: 1.3377\n",
      "Epoch 36/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - loss: 2.9388 - mae: 1.3606 - val_loss: 2.8278 - val_mae: 1.3480\n",
      "Epoch 37/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - loss: 2.9371 - mae: 1.3610 - val_loss: 2.8364 - val_mae: 1.3537\n",
      "Epoch 38/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 2.9402 - mae: 1.3615 - val_loss: 2.7935 - val_mae: 1.3263\n",
      "Epoch 39/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 2.9315 - mae: 1.3587 - val_loss: 2.8009 - val_mae: 1.3276\n",
      "Epoch 40/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 2.9397 - mae: 1.3614 - val_loss: 2.8478 - val_mae: 1.3650\n",
      "Epoch 41/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 2.9176 - mae: 1.3558 - val_loss: 2.8193 - val_mae: 1.3422\n",
      "Epoch 42/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 2.9246 - mae: 1.3563 - val_loss: 2.8321 - val_mae: 1.3483\n",
      "Epoch 43/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 2.9296 - mae: 1.3581 - val_loss: 2.7783 - val_mae: 1.3290\n",
      "Epoch 44/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 2.9161 - mae: 1.3555 - val_loss: 2.7964 - val_mae: 1.3353\n",
      "Epoch 45/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - loss: 2.9105 - mae: 1.3522 - val_loss: 2.8021 - val_mae: 1.3384\n",
      "Epoch 46/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 2.9106 - mae: 1.3532 - val_loss: 2.8033 - val_mae: 1.3410\n",
      "Epoch 47/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 2.9073 - mae: 1.3520 - val_loss: 2.8140 - val_mae: 1.3519\n",
      "Epoch 48/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 2.9071 - mae: 1.3518 - val_loss: 2.7770 - val_mae: 1.3308\n",
      "Epoch 49/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - loss: 2.9069 - mae: 1.3524 - val_loss: 2.7876 - val_mae: 1.3340\n",
      "Epoch 50/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 2.8950 - mae: 1.3478 - val_loss: 2.7839 - val_mae: 1.3331\n",
      "\u001b[1m2440/2440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 722us/step\n",
      "Dominance - Validation MSE: 2.7839\n",
      "Dominance - Validation Std Dev: 1.6646\n",
      "Dominance - Validation Accuracy: 0.7104\n",
      "Dominance - Validation F1-score: 0.7520\n"
     ]
    }
   ],
   "source": [
    "train_fnn_with_dropout(X_train, Y_train[:, 2], X_val, Y_val[:, 2], \"Dominance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - loss: 5.4584 - mae: 1.9278 - val_loss: 4.5729 - val_mae: 1.7952\n",
      "Epoch 2/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 4.6972 - mae: 1.7870 - val_loss: 4.4276 - val_mae: 1.7488\n",
      "Epoch 3/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 4.5390 - mae: 1.7486 - val_loss: 4.3380 - val_mae: 1.7089\n",
      "Epoch 4/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 4.4455 - mae: 1.7269 - val_loss: 4.3099 - val_mae: 1.7016\n",
      "Epoch 5/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 4.4023 - mae: 1.7162 - val_loss: 4.2773 - val_mae: 1.6667\n",
      "Epoch 6/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 4.3516 - mae: 1.7018 - val_loss: 4.2245 - val_mae: 1.6837\n",
      "Epoch 7/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 4.3273 - mae: 1.6949 - val_loss: 4.2037 - val_mae: 1.6576\n",
      "Epoch 8/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 4.3077 - mae: 1.6905 - val_loss: 4.2152 - val_mae: 1.6979\n",
      "Epoch 9/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 4.2825 - mae: 1.6849 - val_loss: 4.1366 - val_mae: 1.6457\n",
      "Epoch 10/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 4.2614 - mae: 1.6793 - val_loss: 4.1176 - val_mae: 1.6548\n",
      "Epoch 11/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 4.2380 - mae: 1.6728 - val_loss: 4.1346 - val_mae: 1.6793\n",
      "Epoch 12/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 4.2265 - mae: 1.6706 - val_loss: 4.0989 - val_mae: 1.6432\n",
      "Epoch 13/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - loss: 4.2111 - mae: 1.6658 - val_loss: 4.0513 - val_mae: 1.6335\n",
      "Epoch 14/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - loss: 4.1809 - mae: 1.6592 - val_loss: 4.0592 - val_mae: 1.6447\n",
      "Epoch 15/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - loss: 4.1807 - mae: 1.6574 - val_loss: 4.0603 - val_mae: 1.6572\n",
      "Epoch 16/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1ms/step - loss: 4.1759 - mae: 1.6557 - val_loss: 4.0391 - val_mae: 1.6430\n",
      "Epoch 17/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1ms/step - loss: 4.1559 - mae: 1.6513 - val_loss: 4.0341 - val_mae: 1.6490\n",
      "Epoch 18/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 4.1558 - mae: 1.6503 - val_loss: 4.0037 - val_mae: 1.6418\n",
      "Epoch 19/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 4.1419 - mae: 1.6468 - val_loss: 4.0059 - val_mae: 1.6423\n",
      "Epoch 20/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 4.1195 - mae: 1.6426 - val_loss: 3.9692 - val_mae: 1.6175\n",
      "Epoch 21/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step - loss: 4.1295 - mae: 1.6433 - val_loss: 3.9998 - val_mae: 1.6383\n",
      "Epoch 22/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 4.1188 - mae: 1.6405 - val_loss: 3.9916 - val_mae: 1.6194\n",
      "Epoch 23/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 4.0961 - mae: 1.6344 - val_loss: 3.9386 - val_mae: 1.6039\n",
      "Epoch 24/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 4.0970 - mae: 1.6340 - val_loss: 3.9499 - val_mae: 1.6227\n",
      "Epoch 25/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 4.1064 - mae: 1.6375 - val_loss: 3.9523 - val_mae: 1.6182\n",
      "Epoch 26/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 4.0904 - mae: 1.6333 - val_loss: 3.9242 - val_mae: 1.6140\n",
      "Epoch 27/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 4.0764 - mae: 1.6301 - val_loss: 3.9160 - val_mae: 1.6009\n",
      "Epoch 28/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 4.0871 - mae: 1.6332 - val_loss: 3.9113 - val_mae: 1.6002\n",
      "Epoch 29/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 4.0654 - mae: 1.6270 - val_loss: 3.9526 - val_mae: 1.6375\n",
      "Epoch 30/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 4.0667 - mae: 1.6262 - val_loss: 3.9231 - val_mae: 1.6196\n",
      "Epoch 31/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 4.0497 - mae: 1.6229 - val_loss: 3.9022 - val_mae: 1.6094\n",
      "Epoch 32/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - loss: 4.0532 - mae: 1.6236 - val_loss: 3.9210 - val_mae: 1.6201\n",
      "Epoch 33/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - loss: 4.0486 - mae: 1.6229 - val_loss: 3.8669 - val_mae: 1.5812\n",
      "Epoch 34/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 4.0231 - mae: 1.6165 - val_loss: 3.8943 - val_mae: 1.6124\n",
      "Epoch 35/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 4.0371 - mae: 1.6191 - val_loss: 3.8478 - val_mae: 1.5869\n",
      "Epoch 36/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 4.0224 - mae: 1.6149 - val_loss: 3.9318 - val_mae: 1.6265\n",
      "Epoch 37/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2ms/step - loss: 4.0265 - mae: 1.6167 - val_loss: 3.8712 - val_mae: 1.6025\n",
      "Epoch 38/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 4.0329 - mae: 1.6171 - val_loss: 3.8953 - val_mae: 1.6107\n",
      "Epoch 39/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 4.0095 - mae: 1.6112 - val_loss: 3.8672 - val_mae: 1.5978\n",
      "Epoch 40/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 4.0040 - mae: 1.6112 - val_loss: 3.8793 - val_mae: 1.5999\n",
      "Epoch 41/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 4.0076 - mae: 1.6109 - val_loss: 3.8561 - val_mae: 1.6006\n",
      "Epoch 42/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 4.0074 - mae: 1.6120 - val_loss: 3.8599 - val_mae: 1.6047\n",
      "Epoch 43/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - loss: 4.0090 - mae: 1.6119 - val_loss: 3.8705 - val_mae: 1.6052\n",
      "Epoch 44/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 4.0012 - mae: 1.6102 - val_loss: 3.8381 - val_mae: 1.5946\n",
      "Epoch 45/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 3.9850 - mae: 1.6051 - val_loss: 3.8150 - val_mae: 1.5727\n",
      "Epoch 46/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 4.0070 - mae: 1.6101 - val_loss: 3.8103 - val_mae: 1.5664\n",
      "Epoch 47/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 3.9837 - mae: 1.6044 - val_loss: 3.8135 - val_mae: 1.5775\n",
      "Epoch 48/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 3.9830 - mae: 1.6055 - val_loss: 3.8751 - val_mae: 1.6167\n",
      "Epoch 49/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - loss: 3.9795 - mae: 1.6034 - val_loss: 3.7953 - val_mae: 1.5764\n",
      "Epoch 50/50\n",
      "\u001b[1m14640/14640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3ms/step - loss: 3.9689 - mae: 1.6014 - val_loss: 3.7969 - val_mae: 1.5652\n",
      "\u001b[1m2440/2440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
      "Liking - Validation MSE: 3.7969\n",
      "Liking - Validation Std Dev: 1.9485\n",
      "Liking - Validation Accuracy: 0.7154\n",
      "Liking - Validation F1-score: 0.7924\n"
     ]
    }
   ],
   "source": [
    "train_fnn_with_dropout(X_train, Y_train[:, 3], X_val, Y_val[:, 3], \"Liking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 5.5087 - mae: 1.9087 - val_loss: 4.0237 - val_mae: 1.6792\n",
      "Epoch 2/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 4.3430 - mae: 1.7267 - val_loss: 3.8520 - val_mae: 1.6426\n",
      "Epoch 3/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 4.1093 - mae: 1.6745 - val_loss: 3.7470 - val_mae: 1.6045\n",
      "Epoch 4/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 3.9577 - mae: 1.6356 - val_loss: 3.6726 - val_mae: 1.5635\n",
      "Epoch 5/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 3.8274 - mae: 1.6049 - val_loss: 3.6505 - val_mae: 1.5951\n",
      "Epoch 6/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 3.7756 - mae: 1.5932 - val_loss: 3.5397 - val_mae: 1.5492\n",
      "Epoch 7/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 3.6943 - mae: 1.5738 - val_loss: 3.4681 - val_mae: 1.5129\n",
      "Epoch 8/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 3.6356 - mae: 1.5561 - val_loss: 3.4498 - val_mae: 1.5274\n",
      "Epoch 9/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 3.5935 - mae: 1.5467 - val_loss: 3.4117 - val_mae: 1.5143\n",
      "Epoch 10/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 3.5762 - mae: 1.5376 - val_loss: 3.4488 - val_mae: 1.4857\n",
      "Epoch 11/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.5202 - mae: 1.5253 - val_loss: 3.3723 - val_mae: 1.4956\n",
      "Epoch 12/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.5213 - mae: 1.5231 - val_loss: 3.3747 - val_mae: 1.4969\n",
      "Epoch 13/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 3.4973 - mae: 1.5166 - val_loss: 3.3423 - val_mae: 1.4992\n",
      "Epoch 14/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 3.4783 - mae: 1.5086 - val_loss: 3.3080 - val_mae: 1.4775\n",
      "Epoch 15/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 3.4208 - mae: 1.4963 - val_loss: 3.2845 - val_mae: 1.4717\n",
      "Epoch 16/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.4159 - mae: 1.4918 - val_loss: 3.2654 - val_mae: 1.4567\n",
      "Epoch 17/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.4002 - mae: 1.4888 - val_loss: 3.2235 - val_mae: 1.4530\n",
      "Epoch 18/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.3974 - mae: 1.4851 - val_loss: 3.2129 - val_mae: 1.4437\n",
      "Epoch 19/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.3562 - mae: 1.4751 - val_loss: 3.2389 - val_mae: 1.4596\n",
      "Epoch 20/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.3536 - mae: 1.4722 - val_loss: 3.1461 - val_mae: 1.4122\n",
      "Epoch 21/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.3444 - mae: 1.4701 - val_loss: 3.1796 - val_mae: 1.4421\n",
      "Epoch 22/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.3036 - mae: 1.4607 - val_loss: 3.1417 - val_mae: 1.4338\n",
      "Epoch 23/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 3.3028 - mae: 1.4577 - val_loss: 3.1486 - val_mae: 1.4239\n",
      "Epoch 24/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 3.2944 - mae: 1.4535 - val_loss: 3.1090 - val_mae: 1.4066\n",
      "Epoch 25/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 3.2495 - mae: 1.4405 - val_loss: 3.0865 - val_mae: 1.4063\n",
      "Epoch 26/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.2621 - mae: 1.4452 - val_loss: 3.1310 - val_mae: 1.4280\n",
      "Epoch 27/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.2207 - mae: 1.4372 - val_loss: 3.0773 - val_mae: 1.3951\n",
      "Epoch 28/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.2593 - mae: 1.4413 - val_loss: 3.0568 - val_mae: 1.4024\n",
      "Epoch 29/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 3.2484 - mae: 1.4396 - val_loss: 3.0980 - val_mae: 1.4126\n",
      "Epoch 30/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 3.2131 - mae: 1.4300 - val_loss: 3.0546 - val_mae: 1.4047\n",
      "Epoch 31/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 3.2147 - mae: 1.4291 - val_loss: 3.0265 - val_mae: 1.3944\n",
      "Epoch 32/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 3.1832 - mae: 1.4201 - val_loss: 3.0021 - val_mae: 1.3811\n",
      "Epoch 33/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.1791 - mae: 1.4190 - val_loss: 3.0431 - val_mae: 1.4083\n",
      "Epoch 34/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.1793 - mae: 1.4189 - val_loss: 3.0460 - val_mae: 1.3946\n",
      "Epoch 35/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 3.1654 - mae: 1.4158 - val_loss: 3.0332 - val_mae: 1.3992\n",
      "Epoch 36/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 3.1745 - mae: 1.4175 - val_loss: 3.0683 - val_mae: 1.4073\n",
      "Epoch 37/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 3.1552 - mae: 1.4112 - val_loss: 3.0151 - val_mae: 1.3995\n",
      "Epoch 38/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 3.1200 - mae: 1.4039 - val_loss: 3.0013 - val_mae: 1.3855\n",
      "Epoch 39/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.1325 - mae: 1.4057 - val_loss: 2.9628 - val_mae: 1.3751\n",
      "Epoch 40/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.1098 - mae: 1.3992 - val_loss: 2.9587 - val_mae: 1.3778\n",
      "Epoch 41/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 3.1303 - mae: 1.4014 - val_loss: 2.9770 - val_mae: 1.3829\n",
      "Epoch 42/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 3.0998 - mae: 1.3954 - val_loss: 3.0133 - val_mae: 1.3907\n",
      "Epoch 43/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 3.1374 - mae: 1.4017 - val_loss: 2.9466 - val_mae: 1.3678\n",
      "Epoch 44/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 3.1056 - mae: 1.3968 - val_loss: 2.9828 - val_mae: 1.3728\n",
      "Epoch 45/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 3.1051 - mae: 1.3918 - val_loss: 3.0113 - val_mae: 1.3777\n",
      "Epoch 46/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 3.0825 - mae: 1.3906 - val_loss: 2.9588 - val_mae: 1.3622\n",
      "Epoch 47/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 3.0987 - mae: 1.3941 - val_loss: 2.9350 - val_mae: 1.3541\n",
      "Epoch 48/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 3.0965 - mae: 1.3942 - val_loss: 2.9215 - val_mae: 1.3657\n",
      "Epoch 49/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 3.0596 - mae: 1.3861 - val_loss: 2.9066 - val_mae: 1.3545\n",
      "Epoch 50/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 3.0610 - mae: 1.3819 - val_loss: 2.9438 - val_mae: 1.3752\n",
      "\u001b[1m763/763\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step\n",
      "Arousal - Validation MAE: 1.3752\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - loss: 4.3419 - mae: 1.6770 - val_loss: 3.2554 - val_mae: 1.4950\n",
      "Epoch 2/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 3.4740 - mae: 1.5256 - val_loss: 3.1344 - val_mae: 1.4452\n",
      "Epoch 3/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 3.3223 - mae: 1.4876 - val_loss: 3.0851 - val_mae: 1.4404\n",
      "Epoch 4/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 3.2278 - mae: 1.4629 - val_loss: 3.0237 - val_mae: 1.4110\n",
      "Epoch 5/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 3.1562 - mae: 1.4427 - val_loss: 3.0156 - val_mae: 1.4156\n",
      "Epoch 6/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 3.1163 - mae: 1.4339 - val_loss: 2.9479 - val_mae: 1.4026\n",
      "Epoch 7/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.0763 - mae: 1.4169 - val_loss: 2.9192 - val_mae: 1.3921\n",
      "Epoch 8/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 3.0381 - mae: 1.4075 - val_loss: 2.8829 - val_mae: 1.3802\n",
      "Epoch 9/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 2.9649 - mae: 1.3884 - val_loss: 2.8299 - val_mae: 1.3577\n",
      "Epoch 10/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 2.9492 - mae: 1.3820 - val_loss: 2.8216 - val_mae: 1.3517\n",
      "Epoch 11/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 2.9295 - mae: 1.3741 - val_loss: 2.8026 - val_mae: 1.3524\n",
      "Epoch 12/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 2.8878 - mae: 1.3638 - val_loss: 2.7715 - val_mae: 1.3379\n",
      "Epoch 13/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 2.8697 - mae: 1.3558 - val_loss: 2.7522 - val_mae: 1.3305\n",
      "Epoch 14/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8730 - mae: 1.3565 - val_loss: 2.7250 - val_mae: 1.3125\n",
      "Epoch 15/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 2.8145 - mae: 1.3401 - val_loss: 2.7446 - val_mae: 1.3183\n",
      "Epoch 16/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 2.8285 - mae: 1.3415 - val_loss: 2.7164 - val_mae: 1.3055\n",
      "Epoch 17/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 2.8121 - mae: 1.3374 - val_loss: 2.6927 - val_mae: 1.3123\n",
      "Epoch 18/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 2.7753 - mae: 1.3252 - val_loss: 2.6520 - val_mae: 1.2923\n",
      "Epoch 19/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 2.7825 - mae: 1.3281 - val_loss: 2.6577 - val_mae: 1.2999\n",
      "Epoch 20/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.7561 - mae: 1.3187 - val_loss: 2.6569 - val_mae: 1.3076\n",
      "Epoch 21/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.7713 - mae: 1.3228 - val_loss: 2.6566 - val_mae: 1.2982\n",
      "Epoch 22/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 2.7370 - mae: 1.3147 - val_loss: 2.6137 - val_mae: 1.2857\n",
      "Epoch 23/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 2.7293 - mae: 1.3130 - val_loss: 2.6361 - val_mae: 1.2923\n",
      "Epoch 24/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.7128 - mae: 1.3064 - val_loss: 2.6162 - val_mae: 1.2995\n",
      "Epoch 25/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 2.7035 - mae: 1.3027 - val_loss: 2.5662 - val_mae: 1.2689\n",
      "Epoch 26/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 2.6858 - mae: 1.2973 - val_loss: 2.5655 - val_mae: 1.2657\n",
      "Epoch 27/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 2.6951 - mae: 1.2978 - val_loss: 2.5622 - val_mae: 1.2703\n",
      "Epoch 28/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 2.6900 - mae: 1.2953 - val_loss: 2.5438 - val_mae: 1.2621\n",
      "Epoch 29/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 2.6716 - mae: 1.2899 - val_loss: 2.5617 - val_mae: 1.2629\n",
      "Epoch 30/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 2.6565 - mae: 1.2885 - val_loss: 2.5558 - val_mae: 1.2761\n",
      "Epoch 31/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 2.6512 - mae: 1.2834 - val_loss: 2.5842 - val_mae: 1.2871\n",
      "Epoch 32/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 72ms/step - loss: 2.6632 - mae: 1.2876 - val_loss: 2.5679 - val_mae: 1.2779\n",
      "Epoch 33/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.6281 - mae: 1.2759 - val_loss: 2.5387 - val_mae: 1.2595\n",
      "Epoch 34/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.6196 - mae: 1.2750 - val_loss: 2.5312 - val_mae: 1.2657\n",
      "Epoch 35/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.6190 - mae: 1.2731 - val_loss: 2.5125 - val_mae: 1.2392\n",
      "Epoch 36/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.6316 - mae: 1.2766 - val_loss: 2.5134 - val_mae: 1.2533\n",
      "Epoch 37/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.6197 - mae: 1.2750 - val_loss: 2.5186 - val_mae: 1.2619\n",
      "Epoch 38/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.6033 - mae: 1.2695 - val_loss: 2.4736 - val_mae: 1.2283\n",
      "Epoch 39/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 2.6033 - mae: 1.2659 - val_loss: 2.4694 - val_mae: 1.2345\n",
      "Epoch 40/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 2.5946 - mae: 1.2634 - val_loss: 2.4919 - val_mae: 1.2509\n",
      "Epoch 41/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 2.5838 - mae: 1.2599 - val_loss: 2.4809 - val_mae: 1.2454\n",
      "Epoch 42/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.5801 - mae: 1.2600 - val_loss: 2.4662 - val_mae: 1.2371\n",
      "Epoch 43/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.5671 - mae: 1.2577 - val_loss: 2.4873 - val_mae: 1.2277\n",
      "Epoch 44/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.5819 - mae: 1.2604 - val_loss: 2.4858 - val_mae: 1.2458\n",
      "Epoch 45/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.5697 - mae: 1.2568 - val_loss: 2.4376 - val_mae: 1.2244\n",
      "Epoch 46/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.5563 - mae: 1.2510 - val_loss: 2.4426 - val_mae: 1.2186\n",
      "Epoch 47/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.5551 - mae: 1.2522 - val_loss: 2.4658 - val_mae: 1.2423\n",
      "Epoch 48/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.5533 - mae: 1.2553 - val_loss: 2.4711 - val_mae: 1.2429\n",
      "Epoch 49/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.5395 - mae: 1.2455 - val_loss: 2.4239 - val_mae: 1.2184\n",
      "Epoch 50/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.5544 - mae: 1.2515 - val_loss: 2.3914 - val_mae: 1.2040\n",
      "\u001b[1m763/763\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Valence - Validation MAE: 1.2040\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 4.8179 - mae: 1.7778 - val_loss: 3.6624 - val_mae: 1.6066\n",
      "Epoch 2/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.8991 - mae: 1.6230 - val_loss: 3.5314 - val_mae: 1.5567\n",
      "Epoch 3/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.7199 - mae: 1.5838 - val_loss: 3.4218 - val_mae: 1.5215\n",
      "Epoch 4/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.6084 - mae: 1.5584 - val_loss: 3.4098 - val_mae: 1.5287\n",
      "Epoch 5/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.5099 - mae: 1.5351 - val_loss: 3.3027 - val_mae: 1.4955\n",
      "Epoch 6/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.4440 - mae: 1.5143 - val_loss: 3.2378 - val_mae: 1.4617\n",
      "Epoch 7/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.3996 - mae: 1.5041 - val_loss: 3.2638 - val_mae: 1.4692\n",
      "Epoch 8/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.3590 - mae: 1.4915 - val_loss: 3.1934 - val_mae: 1.4536\n",
      "Epoch 9/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.3211 - mae: 1.4809 - val_loss: 3.1975 - val_mae: 1.4645\n",
      "Epoch 10/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.2742 - mae: 1.4668 - val_loss: 3.1396 - val_mae: 1.4436\n",
      "Epoch 11/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.2363 - mae: 1.4563 - val_loss: 3.1754 - val_mae: 1.4589\n",
      "Epoch 12/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.2029 - mae: 1.4510 - val_loss: 3.0739 - val_mae: 1.4282\n",
      "Epoch 13/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.2069 - mae: 1.4487 - val_loss: 3.1544 - val_mae: 1.4524\n",
      "Epoch 14/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.1546 - mae: 1.4334 - val_loss: 3.0378 - val_mae: 1.4168\n",
      "Epoch 15/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.1663 - mae: 1.4351 - val_loss: 3.0599 - val_mae: 1.4361\n",
      "Epoch 16/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.1236 - mae: 1.4240 - val_loss: 3.0376 - val_mae: 1.4171\n",
      "Epoch 17/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.1292 - mae: 1.4236 - val_loss: 2.9560 - val_mae: 1.3847\n",
      "Epoch 18/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.1145 - mae: 1.4186 - val_loss: 2.9633 - val_mae: 1.3924\n",
      "Epoch 19/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.0984 - mae: 1.4135 - val_loss: 2.9267 - val_mae: 1.3697\n",
      "Epoch 20/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.0774 - mae: 1.4087 - val_loss: 2.9042 - val_mae: 1.3700\n",
      "Epoch 21/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.0588 - mae: 1.4014 - val_loss: 2.9142 - val_mae: 1.3778\n",
      "Epoch 22/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.0501 - mae: 1.3980 - val_loss: 2.8894 - val_mae: 1.3614\n",
      "Epoch 23/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.0173 - mae: 1.3902 - val_loss: 2.8942 - val_mae: 1.3673\n",
      "Epoch 24/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.0133 - mae: 1.3899 - val_loss: 2.9404 - val_mae: 1.4001\n",
      "Epoch 25/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.0098 - mae: 1.3875 - val_loss: 2.8643 - val_mae: 1.3578\n",
      "Epoch 26/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.9900 - mae: 1.3823 - val_loss: 2.8809 - val_mae: 1.3573\n",
      "Epoch 27/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.9951 - mae: 1.3817 - val_loss: 2.9315 - val_mae: 1.3836\n",
      "Epoch 28/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.9905 - mae: 1.3815 - val_loss: 2.8262 - val_mae: 1.3450\n",
      "Epoch 29/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.9616 - mae: 1.3719 - val_loss: 2.8385 - val_mae: 1.3401\n",
      "Epoch 30/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.9678 - mae: 1.3739 - val_loss: 2.8509 - val_mae: 1.3525\n",
      "Epoch 31/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.9313 - mae: 1.3607 - val_loss: 2.8290 - val_mae: 1.3435\n",
      "Epoch 32/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.9430 - mae: 1.3643 - val_loss: 2.7894 - val_mae: 1.3345\n",
      "Epoch 33/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.9162 - mae: 1.3579 - val_loss: 2.8079 - val_mae: 1.3391\n",
      "Epoch 34/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.9078 - mae: 1.3570 - val_loss: 2.8231 - val_mae: 1.3431\n",
      "Epoch 35/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8996 - mae: 1.3554 - val_loss: 2.7554 - val_mae: 1.3262\n",
      "Epoch 36/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8996 - mae: 1.3515 - val_loss: 2.8022 - val_mae: 1.3288\n",
      "Epoch 37/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.9129 - mae: 1.3571 - val_loss: 2.7650 - val_mae: 1.3337\n",
      "Epoch 38/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.9052 - mae: 1.3541 - val_loss: 2.7529 - val_mae: 1.3012\n",
      "Epoch 39/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8803 - mae: 1.3460 - val_loss: 2.7480 - val_mae: 1.3254\n",
      "Epoch 40/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.9039 - mae: 1.3535 - val_loss: 2.7122 - val_mae: 1.2963\n",
      "Epoch 41/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8796 - mae: 1.3433 - val_loss: 2.7587 - val_mae: 1.3343\n",
      "Epoch 42/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8628 - mae: 1.3417 - val_loss: 2.7317 - val_mae: 1.3193\n",
      "Epoch 43/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8581 - mae: 1.3386 - val_loss: 2.7129 - val_mae: 1.3156\n",
      "Epoch 44/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8527 - mae: 1.3395 - val_loss: 2.7266 - val_mae: 1.3075\n",
      "Epoch 45/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8532 - mae: 1.3382 - val_loss: 2.6905 - val_mae: 1.3018\n",
      "Epoch 46/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8446 - mae: 1.3362 - val_loss: 2.7369 - val_mae: 1.3261\n",
      "Epoch 47/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8582 - mae: 1.3395 - val_loss: 2.7035 - val_mae: 1.3062\n",
      "Epoch 48/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8398 - mae: 1.3314 - val_loss: 2.6436 - val_mae: 1.2874\n",
      "Epoch 49/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8370 - mae: 1.3323 - val_loss: 2.6849 - val_mae: 1.2984\n",
      "Epoch 50/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8609 - mae: 1.3374 - val_loss: 2.7107 - val_mae: 1.3194\n",
      "\u001b[1m763/763\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Dominance - Validation MAE: 1.3194\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 4.8365 - mae: 1.7146 - val_loss: 3.2822 - val_mae: 1.4178\n",
      "Epoch 2/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.6379 - mae: 1.4917 - val_loss: 3.1886 - val_mae: 1.3659\n",
      "Epoch 3/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.4562 - mae: 1.4449 - val_loss: 3.1597 - val_mae: 1.3858\n",
      "Epoch 4/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.3085 - mae: 1.4047 - val_loss: 3.0811 - val_mae: 1.3173\n",
      "Epoch 5/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.2693 - mae: 1.3933 - val_loss: 3.0213 - val_mae: 1.3337\n",
      "Epoch 6/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.2055 - mae: 1.3764 - val_loss: 3.0768 - val_mae: 1.3634\n",
      "Epoch 7/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.1423 - mae: 1.3584 - val_loss: 2.9818 - val_mae: 1.3360\n",
      "Epoch 8/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 3.1057 - mae: 1.3467 - val_loss: 2.9617 - val_mae: 1.3101\n",
      "Epoch 9/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 3.0410 - mae: 1.3309 - val_loss: 2.9694 - val_mae: 1.3336\n",
      "Epoch 10/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 3.0518 - mae: 1.3310 - val_loss: 2.9265 - val_mae: 1.2852\n",
      "Epoch 11/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 3.0062 - mae: 1.3158 - val_loss: 2.9049 - val_mae: 1.2835\n",
      "Epoch 12/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 2.9887 - mae: 1.3108 - val_loss: 2.9015 - val_mae: 1.2662\n",
      "Epoch 13/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.9762 - mae: 1.3057 - val_loss: 2.8754 - val_mae: 1.2841\n",
      "Epoch 14/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 2.9475 - mae: 1.2997 - val_loss: 2.8688 - val_mae: 1.2883\n",
      "Epoch 15/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 2.9030 - mae: 1.2868 - val_loss: 2.8283 - val_mae: 1.2521\n",
      "Epoch 16/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 2.9310 - mae: 1.2892 - val_loss: 2.8130 - val_mae: 1.2536\n",
      "Epoch 17/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.9160 - mae: 1.2856 - val_loss: 2.8196 - val_mae: 1.2421\n",
      "Epoch 18/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.9013 - mae: 1.2780 - val_loss: 2.7972 - val_mae: 1.2459\n",
      "Epoch 19/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.9037 - mae: 1.2805 - val_loss: 2.7866 - val_mae: 1.2522\n",
      "Epoch 20/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8702 - mae: 1.2708 - val_loss: 2.7766 - val_mae: 1.2401\n",
      "Epoch 21/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8534 - mae: 1.2656 - val_loss: 2.7812 - val_mae: 1.2192\n",
      "Epoch 22/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.8641 - mae: 1.2680 - val_loss: 2.7812 - val_mae: 1.2674\n",
      "Epoch 23/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8558 - mae: 1.2634 - val_loss: 2.7657 - val_mae: 1.2391\n",
      "Epoch 24/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8392 - mae: 1.2598 - val_loss: 2.7199 - val_mae: 1.2324\n",
      "Epoch 25/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.8247 - mae: 1.2572 - val_loss: 2.7138 - val_mae: 1.2115\n",
      "Epoch 26/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.8025 - mae: 1.2513 - val_loss: 2.6932 - val_mae: 1.2167\n",
      "Epoch 27/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8003 - mae: 1.2492 - val_loss: 2.7095 - val_mae: 1.2399\n",
      "Epoch 28/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.8115 - mae: 1.2516 - val_loss: 2.6994 - val_mae: 1.2227\n",
      "Epoch 29/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.7942 - mae: 1.2445 - val_loss: 2.6956 - val_mae: 1.2258\n",
      "Epoch 30/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.7962 - mae: 1.2464 - val_loss: 2.6961 - val_mae: 1.2219\n",
      "Epoch 31/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.7891 - mae: 1.2454 - val_loss: 2.6707 - val_mae: 1.2164\n",
      "Epoch 32/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.7683 - mae: 1.2394 - val_loss: 2.6487 - val_mae: 1.2081\n",
      "Epoch 33/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.7549 - mae: 1.2358 - val_loss: 2.6655 - val_mae: 1.1913\n",
      "Epoch 34/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.7627 - mae: 1.2374 - val_loss: 2.6889 - val_mae: 1.2276\n",
      "Epoch 35/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.7520 - mae: 1.2351 - val_loss: 2.6259 - val_mae: 1.2035\n",
      "Epoch 36/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.7485 - mae: 1.2339 - val_loss: 2.6353 - val_mae: 1.2021\n",
      "Epoch 37/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.7473 - mae: 1.2334 - val_loss: 2.6363 - val_mae: 1.2066\n",
      "Epoch 38/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.7225 - mae: 1.2268 - val_loss: 2.6198 - val_mae: 1.1916\n",
      "Epoch 39/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.7147 - mae: 1.2233 - val_loss: 2.6380 - val_mae: 1.2075\n",
      "Epoch 40/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.7210 - mae: 1.2273 - val_loss: 2.6494 - val_mae: 1.2134\n",
      "Epoch 41/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.7013 - mae: 1.2187 - val_loss: 2.6202 - val_mae: 1.1950\n",
      "Epoch 42/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.7061 - mae: 1.2219 - val_loss: 2.6021 - val_mae: 1.1796\n",
      "Epoch 43/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.6957 - mae: 1.2148 - val_loss: 2.6273 - val_mae: 1.2083\n",
      "Epoch 44/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 2.6815 - mae: 1.2132 - val_loss: 2.5826 - val_mae: 1.1910\n",
      "Epoch 45/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.6832 - mae: 1.2130 - val_loss: 2.5916 - val_mae: 1.1997\n",
      "Epoch 46/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 2.6823 - mae: 1.2101 - val_loss: 2.5823 - val_mae: 1.1866\n",
      "Epoch 47/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 2.6732 - mae: 1.2101 - val_loss: 2.5554 - val_mae: 1.1759\n",
      "Epoch 48/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 2.6641 - mae: 1.2077 - val_loss: 2.5758 - val_mae: 1.1885\n",
      "Epoch 49/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 2.6768 - mae: 1.2106 - val_loss: 2.5676 - val_mae: 1.1776\n",
      "Epoch 50/50\n",
      "\u001b[1m4575/4575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 2.6565 - mae: 1.2056 - val_loss: 2.6074 - val_mae: 1.1998\n",
      "\u001b[1m763/763\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Liking - Validation MAE: 1.1998\n",
      "Arousal MAE: 1.3752215283409495\n",
      "Valence MAE: 1.204033877135105\n",
      "Dominance MAE: 1.319412142915413\n",
      "Liking MAE: 1.199772147076638\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "def train_fnn_with_dropout(X_train, Y_train, X_val, Y_val, feature_name):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),  # Dropout layer with 30% dropout rate\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),  # Dropout layer with 30% dropout rate\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),  # Dropout layer with 30% dropout rate\n",
    "        tf.keras.layers.Dense(1)  # Output layer for single regression target\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "    history = model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_data=(X_val, Y_val), verbose=1)\n",
    "\n",
    "    Y_val_pred = model.predict(X_val).flatten()\n",
    "    \n",
    "    # Calculate and print MAE\n",
    "    mae = mean_absolute_error(Y_val, Y_val_pred)\n",
    "    print(f\"{feature_name} - Validation MAE: {mae:.4f}\")\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Re-train and get MAE for each feature\n",
    "mae_arousal = train_fnn_with_dropout(X_train, Y_train[:, 0], X_val, Y_val[:, 0], \"Arousal\")\n",
    "mae_valence = train_fnn_with_dropout(X_train, Y_train[:, 1], X_val, Y_val[:, 1], \"Valence\")\n",
    "mae_dominance = train_fnn_with_dropout(X_train, Y_train[:, 2], X_val, Y_val[:, 2], \"Dominance\")\n",
    "mae_liking = train_fnn_with_dropout(X_train, Y_train[:, 3], X_val, Y_val[:, 3], \"Liking\")\n",
    "\n",
    "print(f\"Arousal MAE: {mae_arousal}\")\n",
    "print(f\"Valence MAE: {mae_valence}\")\n",
    "print(f\"Dominance MAE: {mae_dominance}\")\n",
    "print(f\"Liking MAE: {mae_liking}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
