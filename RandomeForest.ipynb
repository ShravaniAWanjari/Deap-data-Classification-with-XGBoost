{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pickle\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score\n",
    "from scipy.signal import welch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = [1,2,3,4,6,11,13,17,19,20,21,25,29,31] #14 Channels chosen to fit Emotiv Epoch+\n",
    "band = [4,8,12,16,25,45] #5 bands\n",
    "window_size = 256 #Averaging band power of 2 sec\n",
    "step_size = 16 #Each 0.125 sec update once\n",
    "sample_rate = 128 #Sampling rate of 128 Hz\n",
    "subjectList = ['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_power(data, band, sample_rate):\n",
    "    \"\"\"Calculate band power for a given signal.\"\"\"\n",
    "    freqs, psd = welch(data, sample_rate, nperseg=sample_rate*2)\n",
    "    bandpower = []\n",
    "    for (low, high) in zip(band[:-1], band[1:]):\n",
    "        idx_band = np.logical_and(freqs >= low, freqs < high)\n",
    "        bandpower.append(np.sum(psd[idx_band]))\n",
    "    return bandpower\n",
    "\n",
    "def FFT_Processing(sub, channel, band, window_size, step_size, sample_rate):\n",
    "    '''\n",
    "    arguments:  string subject\n",
    "                list channel indices\n",
    "                list band\n",
    "                int window size for FFT\n",
    "                int step size for FFT\n",
    "                int sample rate for FFT\n",
    "    return:     void\n",
    "    '''\n",
    "    meta = []\n",
    "    with open(f'data_preprocessed_python/s{sub}.dat', 'rb') as file:\n",
    "        subject = pickle.load(file, encoding='latin1')  \n",
    "\n",
    "        for i in range(40): \n",
    "            data = subject[\"data\"][i]\n",
    "            labels = subject[\"labels\"][i]\n",
    "            start = 0\n",
    "\n",
    "            while start + window_size < data.shape[1]:\n",
    "                meta_array = []\n",
    "                meta_data = []  \n",
    "                for j in channel:\n",
    "                    X = data[j][start: start + window_size] \n",
    "                    Y = band_power(X, band, sample_rate)  \n",
    "                    meta_data = meta_data + list(Y)\n",
    "\n",
    "                meta_array.append(np.array(meta_data))\n",
    "                meta_array.append(labels)\n",
    "\n",
    "                meta.append(np.array(meta_array))    \n",
    "                start += step_size\n",
    "                \n",
    "        meta = np.array(meta)\n",
    "\n",
    "        if not os.path.exists('out'):\n",
    "            os.makedirs('out')\n",
    "\n",
    "        np.save(f'out/s{sub}', meta, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "\n",
    "\n",
    "def testing(M, L, model):\n",
    "    '''\n",
    "    arguments:  M: testing dataset\n",
    "                L: testing dataset label\n",
    "                model: scikit-learn model\n",
    "\n",
    "    return:     void\n",
    "    '''\n",
    "    output = model.predict(M[0:468480:32])\n",
    "    label = L[0:468480:32]\n",
    "\n",
    "    k = 0\n",
    "    l = 0\n",
    "\n",
    "    for i in range(len(label)):\n",
    "        k = k + (output[i] - label[i]) ** 2 \n",
    "\n",
    "      \n",
    "        if (output[i] > 5 and label[i] > 5) or (output[i] < 5 and label[i] < 5):\n",
    "            l += 1\n",
    "\n",
    "    print(\"l2 error:\", k / len(label), \"classification accuracy:\", l / len(label), l, len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shrav\\.conda\\envs\\testenv\\lib\\site-packages\\ipykernel_launcher.py:44: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "for subjects in subjectList:\n",
    "    FFT_Processing(subjects, channel, band, window_size, step_size, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset: (468480, 70) (468480, 4)\n",
      "testing dataset: (78080, 70) (78080, 4)\n",
      "validation dataset: (78080, 70) (78080, 4)\n"
     ]
    }
   ],
   "source": [
    "data_training = []\n",
    "label_training = []\n",
    "data_testing = []\n",
    "label_testing = []\n",
    "data_validation = []\n",
    "label_validation = []\n",
    "\n",
    "for subjects in subjectList:\n",
    "    file_path = os.path.join('out', f's{subjects}.npy')\n",
    "    \n",
    "    with open(file_path, 'rb') as file:\n",
    "        sub = np.load(file, allow_pickle=True)\n",
    "        for i in range(sub.shape[0]):\n",
    "            if i % 8 == 0:\n",
    "                data_testing.append(sub[i][0])\n",
    "                label_testing.append(sub[i][1])\n",
    "            elif i % 8 == 1:\n",
    "                data_validation.append(sub[i][0])\n",
    "                label_validation.append(sub[i][1])\n",
    "            else:\n",
    "                data_training.append(sub[i][0])\n",
    "                label_training.append(sub[i][1])\n",
    "\n",
    "\n",
    "np.save(os.path.join('out', 'data_training'), np.array(data_training), allow_pickle=True, fix_imports=True)\n",
    "np.save(os.path.join('out', 'label_training'), np.array(label_training), allow_pickle=True, fix_imports=True)\n",
    "print(\"training dataset:\", np.array(data_training).shape, np.array(label_training).shape)\n",
    "\n",
    "np.save(os.path.join('out', 'data_testing'), np.array(data_testing), allow_pickle=True, fix_imports=True)\n",
    "np.save(os.path.join('out', 'label_testing'), np.array(label_testing), allow_pickle=True, fix_imports=True)\n",
    "print(\"testing dataset:\", np.array(data_testing).shape, np.array(label_testing).shape)\n",
    "\n",
    "np.save(os.path.join('out', 'data_validation'), np.array(data_validation), allow_pickle=True, fix_imports=True)\n",
    "np.save(os.path.join('out', 'label_validation'), np.array(label_validation), allow_pickle=True, fix_imports=True)\n",
    "print(\"validation dataset:\", np.array(data_validation).shape, np.array(label_validation).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:20: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:20: SyntaxWarning: invalid escape sequence '\\l'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5680\\274357244.py:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  with open('out\\data_training.npy', 'rb') as fileTrain:\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5680\\274357244.py:4: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  with open('out\\label_training.npy', 'rb') as fileTrainL:\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5680\\274357244.py:17: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  with open('out\\data_validation.npy', 'rb') as fileTrain:\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5680\\274357244.py:20: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  with open('out\\label_validation.npy', 'rb') as fileTrainL:\n"
     ]
    }
   ],
   "source": [
    "with open('out\\data_training.npy', 'rb') as fileTrain:\n",
    "    X  = np.load(fileTrain)\n",
    "    \n",
    "with open('out\\label_training.npy', 'rb') as fileTrainL:\n",
    "    Y  = np.load(fileTrainL)\n",
    "    \n",
    "X = normalize(X)\n",
    "Z = np.ravel(Y[:, [1]])\n",
    "\n",
    "Arousal_Train = np.ravel(Y[:, [0]])\n",
    "Valence_Train = np.ravel(Y[:, [1]])\n",
    "Domain_Train = np.ravel(Y[:, [2]])\n",
    "Like_Train = np.ravel(Y[:, [3]])\n",
    "\n",
    "\n",
    "\n",
    "with open('out\\data_validation.npy', 'rb') as fileTrain:\n",
    "    M  = np.load(fileTrain)\n",
    "    \n",
    "with open('out\\label_validation.npy', 'rb') as fileTrainL:\n",
    "    N  = np.load(fileTrainL)\n",
    "\n",
    "M = normalize(M)\n",
    "L = np.ravel(N[:, [1]])\n",
    "\n",
    "Arousal_Test = np.ravel(N[:, [0]])\n",
    "Valence_Test = np.ravel(N[:, [1]])\n",
    "Domain_Test = np.ravel(N[:, [2]])\n",
    "Like_Test = np.ravel(N[:, [3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing different number of estimators to compare performace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 512 - l2 error: 1.9218373778684024, classification accuracy: 0.8372950819672131\n",
      "n_estimators: 600 - l2 error: 1.9068313006193074, classification accuracy: 0.8381147540983607\n",
      "n_estimators: 800 - l2 error: 1.918188828644976, classification accuracy: 0.840983606557377\n",
      "n_estimators: 1000 - l2 error: 1.9076483796302401, classification accuracy: 0.8385245901639344\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate model performance\n",
    "def evaluate_model(n_estimators, X_train, y_train, X_test, y_test):\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, n_jobs=6)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    accuracy = sum((predictions > 5) == (y_test > 5)) / len(predictions)\n",
    "    print(f\"n_estimators: {n_estimators} - l2 error: {mse}, classification accuracy: {accuracy}\")\n",
    "    return mse, accuracy\n",
    "\n",
    "# Define the training and testing datasets\n",
    "X_train = X[0:468480:32]\n",
    "y_train = Valence_Train[0:468480:32]\n",
    "X_test = M[0:78080:32]\n",
    "y_test = Valence_Test[0:78080:32]\n",
    "\n",
    "# Test with different numbers of estimators\n",
    "for n in [512,600, 800, 1000]:\n",
    "    evaluate_model(n, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 600 eliminators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.505508366623144, Classification Accuracy: 0.865983606557377\n",
      "Standard Deviation of Predictions: 0.9815188453257646\n",
      "F1 Score: 0.903397341211226\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 650\n",
    "min_samples_leaf = 1  \n",
    "n_jobs = 6  \n",
    "\n",
    "\n",
    "Lik_R = RandomForestRegressor(n_estimators=n_estimators, min_samples_leaf=min_samples_leaf, n_jobs=n_jobs)\n",
    "Lik_R.fit(X[0:468480:32], Like_Train[0:468480:32])\n",
    "\n",
    "\n",
    "def testing(X_test, y_test, model):\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    accuracy = sum((predictions > 5) == (y_test > 5)) / len(predictions)\n",
    "    std_dev = np.std(predictions)\n",
    "    f1 = f1_score((y_test > 5), (predictions > 5))\n",
    "    print(f\"MSE: {mse}, Classification Accuracy: {accuracy}\")\n",
    "    print(f\"Standard Deviation of Predictions: {std_dev}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "\n",
    "testing(M[0:78080:32], Like_Test[0:78080:32], Lik_R)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.8486444326771718, Classification Accuracy: 0.8385245901639344\n",
      "Standard Deviation of Predictions: 1.0977129969113386\n",
      "F1 Score: 0.8697951090548579\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 650\n",
    "min_samples_leaf = 1  \n",
    "n_jobs = 6  # Number of parallel jobs for fitting\n",
    "\n",
    "# Train and evaluate the Dominance model\n",
    "Dom_R = RandomForestRegressor(n_estimators=n_estimators, min_samples_leaf=min_samples_leaf, n_jobs=n_jobs)\n",
    "Dom_R.fit(X[0:468480:32], Domain_Train[0:468480:32])\n",
    "\n",
    "\n",
    "def testing(X_test, y_test, model):\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    accuracy = sum((predictions > 5) == (y_test > 5)) / len(predictions)\n",
    "    std_dev = np.std(predictions)\n",
    "    f1 = f1_score((y_test > 5), (predictions > 5))\n",
    "    print(f\"MSE: {mse}, Classification Accuracy: {accuracy}\")\n",
    "    print(f\"Standard Deviation of Predictions: {std_dev}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "\n",
    "testing(M[0:78080:32], Domain_Test[0:78080:32], Dom_R)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.143780738814238, Classification Accuracy: 0.8213114754098361\n",
      "Standard Deviation of Predictions: 0.925116785044467\n",
      "F1 Score: 0.8474457662701189\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 650\n",
    "min_samples_leaf = 1 \n",
    "n_jobs = 6  # Number of parallel jobs for fitting\n",
    "\n",
    "# Train and evaluate the Arousal model\n",
    "Aro_R = RandomForestRegressor(n_estimators=n_estimators, min_samples_leaf=min_samples_leaf, n_jobs=n_jobs)\n",
    "Aro_R.fit(X[0:468480:32], Arousal_Train[0:468480:32])\n",
    "\n",
    "\n",
    "def testing(X_test, y_test, model):\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    accuracy = sum((predictions > 5) == (y_test > 5)) / len(predictions)\n",
    "    std_dev = np.std(predictions)\n",
    "    f1 = f1_score((y_test > 5), (predictions > 5))\n",
    "    print(f\"MSE: {mse}, Classification Accuracy: {accuracy}\")\n",
    "    print(f\"Standard Deviation of Predictions: {std_dev}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "\n",
    "testing(M[0:78080:32], Arousal_Test[0:78080:32], Aro_R)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 error: 1.9132658834413618, Classification Accuracy: 0.8422131147540983\n",
      "Standard Deviation of Predictions: 0.9253473228831534\n",
      "F1 Score: 0.8649596632760435\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 650\n",
    "min_samples_leaf = 1  \n",
    "n_jobs = 6  # Number of parallel jobs for fitting\n",
    "\n",
    "# Initialize Random Forest Regressor\n",
    "Val_R = RandomForestRegressor(n_estimators=n_estimators, min_samples_leaf=min_samples_leaf, n_jobs=n_jobs)\n",
    "\n",
    "# Fit the regressor to the training data\n",
    "Val_R.fit(X[0:468480:32], Valence_Train[0:468480:32])\n",
    "\n",
    "# Evaluate on testing data\n",
    "predictions = Val_R.predict(M[0:78080:32])\n",
    "mse = mean_squared_error(Valence_Test[0:78080:32], predictions)\n",
    "accuracy = sum((predictions > 5) == (Valence_Test[0:78080:32] > 5)) / len(predictions)\n",
    "\n",
    "print(f\"L2 error: {mse}, Classification Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate standard deviation of predictions\n",
    "std_dev = np.std(predictions)\n",
    "print(f\"Standard Deviation of Predictions: {std_dev}\")\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score((Valence_Test[0:78080:32] > 5), (predictions > 5))\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence - Validation MAE: 1.1088813808322822\n",
      "Dominance - Validation MAE: 1.0850908890290025\n",
      "Arousal - Validation MAE: 1.2048426103404783\n",
      "Liking - Validation MAE: 1.292865510718789\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Function to calculate MAE and print results\n",
    "def calculate_mae(model, X_test, y_test, label):\n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    print(f\"{label} - Validation MAE: {mae}\")\n",
    "\n",
    "\n",
    "calculate_mae(Val_R, M[0:78080:32], Valence_Test[0:78080:32], \"Valence\")\n",
    "\n",
    "# Calculate MAE for Dominance\n",
    "calculate_mae(Dom_R, M[0:78080:32], Domain_Test[0:78080:32], \"Dominance\")\n",
    "\n",
    "# Calculate MAE for Arousal\n",
    "calculate_mae(Aro_R, M[0:78080:32], Arousal_Test[0:78080:32], \"Arousal\")\n",
    "\n",
    "# Calculate MAE for Liking\n",
    "calculate_mae(Lik_R, M[0:78080:32], Like_Test[0:78080:32], \"Liking\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting mne\n",
      "  Downloading mne-1.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from mne) (5.1.1)\n",
      "Collecting jinja2 (from mne)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting lazy-loader>=0.3 (from mne)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: matplotlib>=3.5.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from mne) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from mne) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from mne) (24.0)\n",
      "Collecting pooch>=1.5 (from mne)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: scipy>=1.7.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from mne) (1.13.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from mne) (4.66.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.5.0->mne) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.5.0->mne) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.5.0->mne) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.5.0->mne) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.5.0->mne) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.5.0->mne) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pooch>=1.5->mne) (4.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pooch>=1.5->mne) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->mne) (2.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->mne) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.6.2)\n",
      "Downloading mne-1.7.0-py3-none-any.whl (7.4 MB)\n",
      "   ---------------------------------------- 0.0/7.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/7.4 MB 1.9 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.2/7.4 MB 3.7 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.5/7.4 MB 5.4 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.9/7.4 MB 6.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.1/7.4 MB 5.7 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.2/7.4 MB 5.5 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.3/7.4 MB 5.4 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.3/7.4 MB 5.4 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.3/7.4 MB 5.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.8/7.4 MB 4.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.0/7.4 MB 4.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.2/7.4 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.3/7.4 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.5/7.4 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.5/7.4 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.5/7.4 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.5/7.4 MB 4.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.6/7.4 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.1/7.4 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.4/7.4 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.6/7.4 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.7/7.4 MB 4.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.9/7.4 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.1/7.4 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.3/7.4 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.5/7.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.6/7.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.8/7.4 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.9/7.4 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.1/7.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.3/7.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 5.4/7.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.6/7.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.7/7.4 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.9/7.4 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.1/7.4 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.2/7.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.4/7.4 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.5/7.4 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.5/7.4 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.5/7.4 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.8/7.4 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.2/7.4 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.4/7.4 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.4/7.4 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.6/64.6 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.3/133.3 kB 8.2 MB/s eta 0:00:00\n",
      "Installing collected packages: lazy-loader, jinja2, pooch, mne\n",
      "Successfully installed jinja2-3.1.4 lazy-loader-0.4 mne-1.7.0 pooch-1.8.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:\n",
      "[[array([7.87144981e+02, 3.77151846e+01, 4.32964068e+01, 7.62226562e+01,\n",
      "         1.08990425e+02, 4.81212478e+02, 7.64365890e+01, 6.84873556e+01,\n",
      "         9.49679870e+01, 1.48996786e+02, 1.19034088e+04, 1.28909701e+03,\n",
      "         1.04585046e+03, 1.11679837e+03, 1.91894730e+03, 5.57375580e+02,\n",
      "         8.01786133e+01, 6.91122706e+01, 6.60244881e+01, 1.47913336e+02,\n",
      "         1.47408972e+03, 1.11865534e+02, 1.03658569e+02, 1.12319744e+02,\n",
      "         1.93100540e+02, 1.86821214e+03, 1.13156530e+02, 1.20627550e+02,\n",
      "         8.07700412e+01, 2.12460194e+02, 2.61552034e+03, 2.14300810e+02,\n",
      "         2.07436001e+02, 1.96798426e+02, 3.75748378e+02, 1.05539743e+01,\n",
      "         4.73313102e+00, 2.18818934e+00, 2.32655896e+01, 3.11143297e+01,\n",
      "         1.14535920e+03, 1.30416770e+02, 1.17319048e+02, 1.30780650e+02,\n",
      "         1.83715690e+02, 3.51999124e+03, 2.80068108e+02, 2.36238632e+02,\n",
      "         2.28704726e+02, 4.02428187e+02, 1.62173991e+03, 1.11358592e+02,\n",
      "         9.23908411e+01, 9.13638390e+01, 1.70163283e+02, 2.29515960e+03,\n",
      "         2.21577332e+02, 2.05311200e+02, 2.51617363e+02, 4.04404761e+02,\n",
      "         1.36174481e+03, 1.28080274e+02, 1.16019432e+02, 1.34713671e+02,\n",
      "         2.17047362e+02, 2.04735693e+03, 1.80844853e+02, 1.64176425e+02,\n",
      "         1.89062755e+02, 3.23481555e+02])\n",
      "  array([6.27, 4.03, 7.41, 6.5 ])]\n",
      " [array([1.00801696e+03, 6.03523429e+01, 4.07776494e+01, 6.85673704e+01,\n",
      "         1.01054403e+02, 4.97500008e+02, 9.47837777e+01, 7.88643788e+01,\n",
      "         9.30331903e+01, 1.46503532e+02, 1.34129012e+04, 1.66451933e+03,\n",
      "         1.19844892e+03, 1.11259486e+03, 1.81202461e+03, 5.70476165e+02,\n",
      "         1.08891839e+02, 7.97721914e+01, 6.65879289e+01, 1.50169764e+02,\n",
      "         1.72153145e+03, 1.54242519e+02, 1.15650124e+02, 1.10495976e+02,\n",
      "         1.79438586e+02, 2.28247012e+03, 1.62821654e+02, 1.30255493e+02,\n",
      "         8.49526652e+01, 1.95607460e+02, 2.92780759e+03, 2.81307108e+02,\n",
      "         2.33164036e+02, 2.01391836e+02, 3.43398215e+02, 8.44018189e+00,\n",
      "         4.71435902e+00, 2.78395241e+00, 2.05483838e+01, 3.34371588e+01,\n",
      "         1.32238093e+03, 1.85436486e+02, 1.36715865e+02, 1.28332104e+02,\n",
      "         1.76913446e+02, 4.21879241e+03, 3.66083847e+02, 2.64774917e+02,\n",
      "         2.35656191e+02, 3.70703500e+02, 1.94950803e+03, 1.41360957e+02,\n",
      "         1.02341809e+02, 9.22833817e+01, 1.54740818e+02, 2.54059881e+03,\n",
      "         3.10794368e+02, 2.32148592e+02, 2.42671726e+02, 3.84879670e+02,\n",
      "         1.52151160e+03, 1.78408875e+02, 1.31109866e+02, 1.32463000e+02,\n",
      "         2.07532159e+02, 2.27042875e+03, 2.33595774e+02, 1.83556596e+02,\n",
      "         1.87261189e+02, 3.07800869e+02])\n",
      "  array([6.27, 4.03, 7.41, 6.5 ])]\n",
      " [array([1.73086875e+03, 1.28050930e+02, 5.13491845e+01, 6.57657681e+01,\n",
      "         1.04498278e+02, 6.62183105e+02, 1.26656193e+02, 9.31099721e+01,\n",
      "         9.95435152e+01, 1.40198752e+02, 1.93596414e+04, 2.48679315e+03,\n",
      "         1.49353869e+03, 1.24323839e+03, 1.74243009e+03, 7.37375380e+02,\n",
      "         1.53812840e+02, 9.54675694e+01, 7.62714996e+01, 1.48475852e+02,\n",
      "         2.59858435e+03, 2.60224950e+02, 1.45804002e+02, 1.21630718e+02,\n",
      "         1.72392104e+02, 3.59153649e+03, 2.92256887e+02, 1.60279790e+02,\n",
      "         1.04259428e+02, 1.85757064e+02, 4.19774324e+03, 4.34365461e+02,\n",
      "         2.88759404e+02, 2.34255051e+02, 3.24277580e+02, 6.91072131e+00,\n",
      "         5.06998856e+00, 3.43697843e+00, 1.86851448e+01, 3.52807777e+01,\n",
      "         1.95611494e+03, 2.86345208e+02, 1.69308331e+02, 1.34281123e+02,\n",
      "         1.75031444e+02, 6.59289789e+03, 6.04923782e+02, 3.36626683e+02,\n",
      "         2.71779396e+02, 3.60765459e+02, 3.09916815e+03, 2.43490609e+02,\n",
      "         1.32531063e+02, 1.06684612e+02, 1.50587649e+02, 3.58335279e+03,\n",
      "         4.93786177e+02, 2.86002254e+02, 2.60271381e+02, 3.70573345e+02,\n",
      "         2.16084600e+03, 2.83397525e+02, 1.61064925e+02, 1.47608200e+02,\n",
      "         2.01770345e+02, 3.20128365e+03, 3.59197262e+02, 2.27038590e+02,\n",
      "         2.05072536e+02, 2.98907061e+02])\n",
      "  array([6.27, 4.03, 7.41, 6.5 ])]\n",
      " ...\n",
      " [array([5.98222265e+03, 1.32740783e+03, 3.78886510e+02, 2.50966261e+02,\n",
      "         2.70382551e+02, 4.21681152e+03, 1.66836921e+03, 6.15492179e+02,\n",
      "         3.13475244e+02, 5.63693737e+02, 9.53719596e+04, 3.46208869e+04,\n",
      "         1.23915558e+04, 6.14946752e+03, 7.03903851e+03, 4.96880888e+03,\n",
      "         1.92818563e+03, 7.94317574e+02, 4.31273148e+02, 6.08592804e+02,\n",
      "         1.12857748e+04, 3.50377106e+03, 1.13449200e+03, 5.30523025e+02,\n",
      "         5.28271522e+02, 1.29721229e+04, 3.70191388e+03, 1.17725251e+03,\n",
      "         6.05356631e+02, 5.95300896e+02, 1.95510507e+04, 6.58347072e+03,\n",
      "         2.26376826e+03, 1.22050756e+03, 1.25163464e+03, 1.51199083e+02,\n",
      "         6.25946640e+01, 3.43350318e+01, 4.33430943e+01, 5.61200788e+01,\n",
      "         9.20975428e+03, 3.05741299e+03, 1.10544872e+03, 6.06306937e+02,\n",
      "         4.60675802e+02, 2.70026667e+04, 8.23925108e+03, 2.48417988e+03,\n",
      "         1.43589496e+03, 1.20937940e+03, 1.15429695e+04, 3.45531457e+03,\n",
      "         1.09923870e+03, 4.62015657e+02, 7.11135637e+02, 1.82475541e+04,\n",
      "         6.75411103e+03, 2.58157828e+03, 1.23784824e+03, 1.64873910e+03,\n",
      "         1.07600139e+04, 3.79592643e+03, 1.39557337e+03, 7.23446853e+02,\n",
      "         6.14258315e+02, 1.57467466e+04, 5.61076986e+03, 1.92067285e+03,\n",
      "         1.00099256e+03, 9.58362698e+02])\n",
      "  array([4.95, 2.9 , 3.69, 4.96])]\n",
      " [array([7.49648862e+03, 1.38966744e+03, 3.74327784e+02, 2.28714645e+02,\n",
      "         2.97708322e+02, 3.78632317e+03, 1.35258716e+03, 5.98396370e+02,\n",
      "         2.74984600e+02, 5.36739495e+02, 9.17874270e+04, 2.95331656e+04,\n",
      "         1.18550228e+04, 5.03968328e+03, 6.61791085e+03, 4.43152111e+03,\n",
      "         1.55656350e+03, 7.88486533e+02, 3.57298472e+02, 5.72875665e+02,\n",
      "         1.16459539e+04, 3.16526303e+03, 1.09651448e+03, 4.70785635e+02,\n",
      "         5.11935803e+02, 1.43311221e+04, 3.45495673e+03, 1.15950409e+03,\n",
      "         5.16827793e+02, 5.65784442e+02, 1.91906371e+04, 5.71886223e+03,\n",
      "         2.18617423e+03, 1.02518500e+03, 1.17875313e+03, 1.44483669e+02,\n",
      "         4.85319720e+01, 3.52965518e+01, 3.76234524e+01, 5.08343713e+01,\n",
      "         9.06267897e+03, 2.68286876e+03, 1.03835013e+03, 5.04261248e+02,\n",
      "         4.33101646e+02, 2.89041255e+04, 7.52794414e+03, 2.40230486e+03,\n",
      "         1.21970738e+03, 1.14092813e+03, 1.29113955e+04, 3.28021204e+03,\n",
      "         1.06550529e+03, 3.90832696e+02, 7.24058632e+02, 1.73136788e+04,\n",
      "         5.72873884e+03, 2.43905471e+03, 1.06013549e+03, 1.62723669e+03,\n",
      "         1.02856934e+04, 3.24136614e+03, 1.33569832e+03, 5.96322588e+02,\n",
      "         5.85780890e+02, 1.51149165e+04, 4.79715287e+03, 1.84140420e+03,\n",
      "         8.30907554e+02, 9.09997250e+02])\n",
      "  array([4.95, 2.9 , 3.69, 4.96])]\n",
      " [array([8.66179405e+03, 1.35926242e+03, 3.46571363e+02, 2.06075258e+02,\n",
      "         3.24682010e+02, 3.11164201e+03, 9.82469221e+02, 5.29968922e+02,\n",
      "         2.33279954e+02, 5.02090332e+02, 8.28259799e+04, 2.29060389e+04,\n",
      "         1.03532235e+04, 3.83149778e+03, 6.06494752e+03, 3.61055695e+03,\n",
      "         1.13239783e+03, 7.13067814e+02, 2.74841791e+02, 5.27311068e+02,\n",
      "         1.13859254e+04, 2.63931131e+03, 9.83533228e+02, 3.90156001e+02,\n",
      "         4.89386779e+02, 1.49691535e+04, 2.99045912e+03, 1.05601332e+03,\n",
      "         4.19619259e+02, 5.28820947e+02, 1.77262240e+04, 4.54383028e+03,\n",
      "         1.93531914e+03, 8.00049794e+02, 1.09581696e+03, 1.30028262e+02,\n",
      "         3.40786553e+01, 3.34193028e+01, 3.29713379e+01, 4.80621768e+01,\n",
      "         8.39658537e+03, 2.15935163e+03, 8.95314894e+02, 3.89735085e+02,\n",
      "         3.97405551e+02, 2.92300998e+04, 6.37706905e+03, 2.14193995e+03,\n",
      "         9.69296295e+02, 1.07119556e+03, 1.36235759e+04, 2.88729804e+03,\n",
      "         9.52728275e+02, 3.20399067e+02, 7.22356033e+02, 1.53324151e+04,\n",
      "         4.38932635e+03, 2.10341650e+03, 8.71729560e+02, 1.56225322e+03,\n",
      "         9.20294189e+03, 2.51192169e+03, 1.16632236e+03, 4.54060894e+02,\n",
      "         5.51155567e+02, 1.35908918e+04, 3.73038944e+03, 1.61384216e+03,\n",
      "         6.41208706e+02, 8.50338882e+02])\n",
      "  array([4.95, 2.9 , 3.69, 4.96])]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the data for the 10th participant\n",
    "data = np.load('out/s11.npy', allow_pickle=True)\n",
    "\n",
    "# Print the entire data\n",
    "print(\"Data:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_connectivity_circle' from 'mne.viz' (C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\mne\\viz\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmne\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmne\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mviz\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m circular_layout, plot_connectivity_circle\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the data from the file\u001b[39;00m\n\u001b[0;32m      7\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout/s01.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'plot_connectivity_circle' from 'mne.viz' (C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\mne\\viz\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from mne.viz import circular_layout, plot_connectivity_circle\n",
    "\n",
    "# Load the data from the file\n",
    "file_path = 'out/s01.npy'\n",
    "data_dict = np.load(file_path, allow_pickle=True).item()\n",
    "\n",
    "data = data_dict['data']\n",
    "labels = data_dict['labels']\n",
    "\n",
    "# Extract dimensions from the loaded data\n",
    "num_trials, num_channels, num_samples = data.shape\n",
    "\n",
    "# Assuming there are 4 labels (valence, arousal, dominance, liking)\n",
    "num_labels = labels.shape[1]\n",
    "\n",
    "# Print information about the loaded data\n",
    "print(f\"Number of trials: {num_trials}\")\n",
    "print(f\"Number of EEG channels: {num_channels}\")\n",
    "print(f\"Number of samples per channel: {num_samples}\")\n",
    "print(f\"Number of labels (emotions): {num_labels}\")\n",
    "\n",
    "# Define channel names (assuming generic names since specific names are not provided)\n",
    "# You can use this list to create your plots if specific channel names are not available\n",
    "channel_names = [f'Channel {i+1}' for i in range(num_channels)]\n",
    "\n",
    "# Prepare data for plotting\n",
    "for label_idx, emotion in enumerate(['valence', 'arousal', 'dominance', 'liking']):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    \n",
    "    # Extract the data and labels for the current emotion\n",
    "    emotion_data = labels[:, label_idx]\n",
    "    connectivity_matrix = data[:, :, 0]  # Assuming we take the first sample for illustration\n",
    "    \n",
    "    # Set up the circular layout\n",
    "    node_order = np.arange(num_channels)\n",
    "    node_angles = circular_layout(channel_names, node_order, start_pos=90,\n",
    "                                  group_boundaries=[0, num_channels // 2])\n",
    "    \n",
    "    # Plot the connectivity circle\n",
    "    plot_connectivity_circle(connectivity_matrix, channel_names, n_lines=None,\n",
    "                             node_angles=node_angles, node_colors=emotion_data,\n",
    "                             title=emotion.capitalize(), fig=fig, colorbar=True)\n",
    "\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
