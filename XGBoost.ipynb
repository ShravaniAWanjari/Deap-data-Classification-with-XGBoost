{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pickle\n",
    "from sklearn.preprocessing import normalize\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score, mean_absolute_error\n",
    "from scipy.signal import welch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = [1,2,3,4,6,11,13,17,19,20,21,25,29,31] #14 Channels chosen to fit Emotiv Epoch+\n",
    "band = [4,8,12,16,25,45] #5 bands\n",
    "window_size = 256 #Averaging band power of 2 sec\n",
    "step_size = 16 #Each 0.125 sec update once\n",
    "sample_rate = 128 #Sampling rate of 128 Hz\n",
    "subjectList = ['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_power(data, band, sample_rate):\n",
    "    \"\"\"Calculate band power for a given signal.\"\"\"\n",
    "    freqs, psd = welch(data, sample_rate, nperseg=sample_rate*2)\n",
    "    bandpower = []\n",
    "    for (low, high) in zip(band[:-1], band[1:]):\n",
    "        idx_band = np.logical_and(freqs >= low, freqs < high)\n",
    "        bandpower.append(np.sum(psd[idx_band]))\n",
    "    return bandpower\n",
    "\n",
    "def FFT_Processing(sub, channel, band, window_size, step_size, sample_rate):\n",
    "    '''\n",
    "    arguments:  string subject\n",
    "                list channel indices\n",
    "                list band\n",
    "                int window size for FFT\n",
    "                int step size for FFT\n",
    "                int sample rate for FFT\n",
    "    return:     void\n",
    "    '''\n",
    "    meta = []\n",
    "    with open(f'data_preprocessed_python/s{sub}.dat', 'rb') as file:\n",
    "        subject = pickle.load(file, encoding='latin1')  \n",
    "\n",
    "        for i in range(40): \n",
    "            data = subject[\"data\"][i]\n",
    "            labels = subject[\"labels\"][i]\n",
    "            start = 0\n",
    "\n",
    "            while start + window_size < data.shape[1]:\n",
    "                meta_array = []\n",
    "                meta_data = []  \n",
    "                for j in channel:\n",
    "                    X = data[j][start: start + window_size] \n",
    "                    Y = band_power(X, band, sample_rate)  \n",
    "                    meta_data = meta_data + list(Y)\n",
    "\n",
    "                meta_array.append(np.array(meta_data))\n",
    "                meta_array.append(labels)\n",
    "\n",
    "                meta.append(np.array(meta_array))    \n",
    "                start += step_size\n",
    "                \n",
    "        meta = np.array(meta)\n",
    "\n",
    "        if not os.path.exists('out'):\n",
    "            os.makedirs('out')\n",
    "\n",
    "        np.save(f'out/s{sub}', meta, allow_pickle=True, fix_imports=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subjects in subjectList:\n",
    "    FFT_Processing(subjects, channel, band, window_size, step_size, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "data_training = []\n",
    "label_training = []\n",
    "data_testing = []\n",
    "label_testing = []\n",
    "data_validation = []\n",
    "label_validation = []\n",
    "\n",
    "for subjects in subjectList:\n",
    "    file_path = os.path.join('out', f's{subjects}.npy')\n",
    "    \n",
    "    with open(file_path, 'rb') as file:\n",
    "        sub = np.load(file, allow_pickle=True)\n",
    "        for i in range(sub.shape[0]):\n",
    "            if i % 8 == 0:\n",
    "                data_testing.append(sub[i][0])\n",
    "                label_testing.append(sub[i][1])\n",
    "            elif i % 8 == 1:\n",
    "                data_validation.append(sub[i][0])\n",
    "                label_validation.append(sub[i][1])\n",
    "            else:\n",
    "                data_training.append(sub[i][0])\n",
    "                label_training.append(sub[i][1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "np.save(os.path.join('out', 'data_training'), np.array(data_training), allow_pickle=True, fix_imports=True)\n",
    "np.save(os.path.join('out', 'label_training'), np.array(label_training), allow_pickle=True, fix_imports=True)\n",
    "print(\"training dataset:\", np.array(data_training).shape, np.array(label_training).shape)\n",
    "\n",
    "np.save(os.path.join('out', 'data_testing'), np.array(data_testing), allow_pickle=True, fix_imports=True)\n",
    "np.save(os.path.join('out', 'label_testing'), np.array(label_testing), allow_pickle=True, fix_imports=True)\n",
    "print(\"testing dataset:\", np.array(data_testing).shape, np.array(label_testing).shape)\n",
    "\n",
    "np.save(os.path.join('out', 'data_validation'), np.array(data_validation), allow_pickle=True, fix_imports=True)\n",
    "np.save(os.path.join('out', 'label_validation'), np.array(label_validation), allow_pickle=True, fix_imports=True)\n",
    "print(\"validation dataset:\", np.array(data_validation).shape, np.array(label_validation).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('out\\data_training.npy', 'rb') as fileTrain:\n",
    "    X  = np.load(fileTrain)\n",
    "    \n",
    "with open('out\\label_training.npy', 'rb') as fileTrainL:\n",
    "    Y  = np.load(fileTrainL)\n",
    "    \n",
    "X = normalize(X)\n",
    "Z = np.ravel(Y[:, [1]])\n",
    "\n",
    "Arousal_Train = np.ravel(Y[:, [0]])\n",
    "Valence_Train = np.ravel(Y[:, [1]])\n",
    "Dominance_Train = np.ravel(Y[:, [2]])\n",
    "Liking_Train = np.ravel(Y[:, [3]])\n",
    "\n",
    "\n",
    "\n",
    "with open('out\\data_validation.npy', 'rb') as fileTrain:\n",
    "    M  = np.load(fileTrain)\n",
    "    \n",
    "with open('out\\label_validation.npy', 'rb') as fileTrainL:\n",
    "    N  = np.load(fileTrainL)\n",
    "\n",
    "M = normalize(M)\n",
    "L = np.ravel(N[:, [1]])\n",
    "\n",
    "Arousal_Test = np.ravel(N[:, [0]])\n",
    "Valence_Test = np.ravel(N[:, [1]])\n",
    "Dominance_Test = np.ravel(N[:, [2]])\n",
    "Liking_Test = np.ravel(N[:, [3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgb.XGBRegressor(n_estimators=800, max_depth=17, learning_rate=0.1, n_jobs=6)\n",
    "\n",
    "xgb_reg.fit(X[0:468480:32], Arousal_Train[0:468480:32])\n",
    "\n",
    "\n",
    "predictions = xgb_reg.predict(M[0:78080:32])\n",
    "\n",
    "\n",
    "mse = mean_squared_error(Arousal_Test[0:78080:32], predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "\n",
    "accuracy = accuracy_score((Arousal_Test[0:78080:32] > 5), (predictions > 5))\n",
    "print(f\"Classification Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "std_dev = np.std(predictions)\n",
    "print(f\"Standard Deviation of Predictions: {std_dev}\")\n",
    "\n",
    "f1 = f1_score((Arousal_Test[0:78080:32] > 5), (predictions > 5))\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "mae = mean_absolute_error(Arousal_Test[0:78080:32], predictions)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgb.XGBRegressor(n_estimators=800, max_depth=12, learning_rate=0.1, n_jobs=6)\n",
    "\n",
    "xgb_reg.fit(X[0:468480:32], Valence_Train[0:468480:32])\n",
    "\n",
    "\n",
    "predictions = xgb_reg.predict(M[0:78080:32])\n",
    "\n",
    "\n",
    "mse = mean_squared_error(Valence_Test[0:78080:32], predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "\n",
    "accuracy = accuracy_score((Valence_Test[0:78080:32] > 5), (predictions > 5))\n",
    "print(f\"Classification Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "std_dev = np.std(predictions)\n",
    "print(f\"Standard Deviation of Predictions: {std_dev}\")\n",
    "\n",
    "f1 = f1_score((Valence_Test[0:78080:32] > 5), (predictions > 5))\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "mae = mean_absolute_error(Valence_Test[0:78080:32], predictions)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgb.XGBRegressor(n_estimators=800, max_depth=12, learning_rate=0.1, n_jobs=6)\n",
    "\n",
    "xgb_reg.fit(X[0:468480:32], Dominance_Train[0:468480:32])\n",
    "\n",
    "\n",
    "predictions = xgb_reg.predict(M[0:78080:32])\n",
    "\n",
    "\n",
    "mse = mean_squared_error(Dominance_Test[0:78080:32], predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "\n",
    "accuracy = accuracy_score((Dominance_Test[0:78080:32] > 5), (predictions > 5))\n",
    "print(f\"Classification Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "std_dev = np.std(predictions)\n",
    "print(f\"Standard Deviation of Predictions: {std_dev}\")\n",
    "\n",
    "f1 = f1_score((Dominance_Test[0:78080:32] > 5), (predictions > 5))\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "mae = mean_absolute_error(Dominance_Test[0:78080:32], predictions)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgb.XGBRegressor(n_estimators=800, max_depth=10, learning_rate=0.1, n_jobs=6)\n",
    "\n",
    "xgb_reg.fit(X[0:468480:32], Liking_Train[0:468480:32])\n",
    "\n",
    "\n",
    "predictions = xgb_reg.predict(M[0:78080:16])\n",
    "\n",
    "\n",
    "mse = mean_squared_error(Liking_Test[0:78080:16], predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "\n",
    "accuracy = accuracy_score((Liking_Test[0:78080:16] > 5), (predictions > 5))\n",
    "print(f\"Classification Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "std_dev = np.std(predictions)\n",
    "print(f\"Standard Deviation of Predictions: {std_dev}\")\n",
    "\n",
    "f1 = f1_score((Liking_Test[0:78080:16] > 5), (predictions > 5))\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "mae = mean_absolute_error(Liking_Test[0:78080:16], predictions)\n",
    "print(f\"Mean Absolute Error: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# List of n_estimators to test\n",
    "n_estimators_list = [100,300,500, 600, 700, 800]\n",
    "\n",
    "# Loop through each n_estimators value\n",
    "for n in n_estimators_list:\n",
    "    # Initialize the model with the current n_estimators value\n",
    "    xgb_reg = xgb.XGBRegressor(n_estimators=n, max_depth=12, learning_rate=0.1, n_jobs=6)\n",
    "    \n",
    "    # Train the model\n",
    "    xgb_reg.fit(X[0:468480:32], Liking_Train[0:468480:32])\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = xgb_reg.predict(M[0:78080:16])\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score((Liking_Test[0:78080:16] > 5), (predictions > 5))\n",
    "    print(f\"n_estimators: {n}, Classification Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of Valence_Train: {Valence_Train.shape}\")\n",
    "print(f\"Shape of M: {M.shape}\")\n",
    "print(f\"Shape of Valence_Test: {Valence_Test.shape}\")\n",
    "\n",
    "# List of n_estimators to test\n",
    "n_estimators_list = [100, 300, 550, 650, 700,800]\n",
    "\n",
    "# Loop through each n_estimators value\n",
    "for n in n_estimators_list:\n",
    "    # Initialize the model with the current n_estimators value\n",
    "    xgb_reg = xgb.XGBRegressor(n_estimators=n, max_depth=12, learning_rate=0.1, n_jobs=6)\n",
    "    \n",
    "    # Train the model\n",
    "    xgb_reg.fit(X[0:468480:32], Valence_Train[0:468480:32])\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = xgb_reg.predict(M[0:78080:16])\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score((Valence_Test[0:78080:16] > 5), (predictions > 5))\n",
    "    print(f\"n_estimators: {n}, Classification Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of Dominance_Train: {Dominance_Train.shape}\")\n",
    "print(f\"Shape of M: {M.shape}\")\n",
    "print(f\"Shape of Dominance_Test: {Dominance_Test.shape}\")\n",
    "\n",
    "# List of n_estimators to test\n",
    "n_estimators_list = [100,400,500, 600, 700, 800]\n",
    "\n",
    "# Loop through each n_estimators value\n",
    "for n in n_estimators_list:\n",
    "    # Initialize the model with the current n_estimators value\n",
    "    xgb_reg = xgb.XGBRegressor(n_estimators=n, max_depth=12, learning_rate=0.1, n_jobs=6)\n",
    "    \n",
    "    # Train the model\n",
    "    xgb_reg.fit(X[0:468480:32], Dominance_Train[0:468480:32])\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = xgb_reg.predict(M[0:78080:16])\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score((Dominance_Test[0:78080:16] > 5), (predictions > 5))\n",
    "    print(f\"n_estimators: {n}, Classification Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of Arousal_Train: {Arousal_Train.shape}\")\n",
    "print(f\"Shape of M: {M.shape}\")\n",
    "print(f\"Shape of Arousal_Test: {Arousal_Test.shape}\")\n",
    "\n",
    "# List of n_estimators to test\n",
    "n_estimators_list = [100,400,500, 600, 700, 800]\n",
    "\n",
    "# Loop through each n_estimators value\n",
    "for n in n_estimators_list:\n",
    "    # Initialize the model with the current n_estimators value\n",
    "    xgb_reg = xgb.XGBRegressor(n_estimators=n, max_depth=12, learning_rate=0.1, n_jobs=6)\n",
    "    \n",
    "    # Train the model\n",
    "    xgb_reg.fit(X[0:468480:32], Arousal_Train[0:468480:32])\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = xgb_reg.predict(M[0:78080:16])\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score((Arousal_Test[0:78080:16] > 5), (predictions > 5))\n",
    "    print(f\"n_estimators: {n}, Classification Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of Liking_Train: {Liking_Train.shape}\")\n",
    "print(f\"Shape of M: {M.shape}\")\n",
    "print(f\"Shape of Liking_Test: {Liking_Test.shape}\")\n",
    "\n",
    "# List of max_depth values to test\n",
    "max_depth_list = [6, 8, 10, 12, 15,17,19,20,21]\n",
    "\n",
    "# Loop through each max_depth value\n",
    "for max_depth in max_depth_list:\n",
    "    # Initialize the model with the current max_depth value\n",
    "    xgb_reg = xgb.XGBRegressor(n_estimators=800, max_depth=max_depth, learning_rate=0.1, n_jobs=6)\n",
    "    \n",
    "    # Train the model\n",
    "    xgb_reg.fit(X[0:468480:32], Liking_Train[0:468480:32])\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = xgb_reg.predict(M[0:78080:16])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score((Liking_Test[0:78080:16] > 5), (predictions > 5))\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Max Depth: {max_depth}\")\n",
    "\n",
    "    print(f\"  Classification Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Example initialization of Valence_Train and Valence_Test\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of Valence_Train: {Valence_Train.shape}\")\n",
    "print(f\"Shape of M: {M.shape}\")\n",
    "print(f\"Shape of Valence_Test: {Valence_Test.shape}\")\n",
    "\n",
    "# List of max_depth values to test\n",
    "max_depth_list = [ 10, 12, 15,16,17,18,19,20,21]\n",
    "\n",
    "# Loop through each max_depth value\n",
    "for max_depth in max_depth_list:\n",
    "    # Initialize the model with the current max_depth value\n",
    "    xgb_reg = xgb.XGBRegressor(n_estimators=800, max_depth=max_depth, learning_rate=0.1, n_jobs=6)\n",
    "    \n",
    "    # Train the model\n",
    "    xgb_reg.fit(X[0:468480:32], Valence_Train[0:468480:32])\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = xgb_reg.predict(M[0:78080:16])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score((Valence_Test[0:78080:16] > 5), (predictions > 5))\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Max Depth: {max_depth}\")\n",
    "\n",
    "    print(f\"  Classification Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# List of max_depth values to test\n",
    "max_depth_list = [6, 8, 10, 12, 15,17,19,20,21]\n",
    "\n",
    "# Loop through each max_depth value\n",
    "for max_depth in max_depth_list:\n",
    "    # Initialize the model with the current max_depth value\n",
    "    xgb_reg = xgb.XGBRegressor(n_estimators=800, max_depth=max_depth, learning_rate=0.1, n_jobs=6)\n",
    "    \n",
    "    # Train the model\n",
    "    xgb_reg.fit(X[0:468480:32], Arousal_Train[0:468480:32])\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = xgb_reg.predict(M[0:78080:32])\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score((Arousal_Test[0:78080:32] > 5), (predictions > 5))\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Max Depth: {max_depth}\")\n",
    "    print(f\"  Classification Accuracy: {accuracy}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have data arrays similar to Arousal_Train, Arousal_Test, and M for dominance\n",
    "\n",
    "# List of max_depth values to test\n",
    "max_depth_list = [6, 8, 10, 12, 15, 17, 19, 20, 21]\n",
    "\n",
    "# Loop through each max_depth value\n",
    "for max_depth in max_depth_list:\n",
    "    # Initialize the model with the current max_depth value\n",
    "    xgb_reg = xgb.XGBRegressor(n_estimators=800, max_depth=max_depth, learning_rate=0.1, n_jobs=6)\n",
    "    \n",
    "    # Train the model\n",
    "    xgb_reg.fit(X[0:468480:32], Dominance_Train[0:468480:32])  # Assuming Dominance_Train is your training data for dominance\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = xgb_reg.predict(M[0:78080:32])  # Assuming M is your test data for dominance\n",
    "    \n",
    "    # Since this is regression, you might want to threshold predictions for classification purposes\n",
    "    # Example: Assuming dominance values > 5 are considered high dominance\n",
    "    dominance_predictions = (predictions > 5)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score((Dominance_Test[0:78080:32] > 5), dominance_predictions)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Max Depth: {max_depth}\")\n",
    "    print(f\"  Classification Accuracy: {accuracy}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
